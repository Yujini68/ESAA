{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 74935,
          "sourceType": "datasetVersion",
          "datasetId": 42674
        }
      ],
      "dockerImageVersionId": 29852,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yujini68/ESAA/blob/main/%EA%B3%BC%EC%A0%9C_0923_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id='Top'></a>\n",
        "<center>\n",
        "    <h1><u><b>Mall Customers Segmentation</b></u></h1>\n",
        "<h3>Author: Robert Kwiatkowski</h3>\n",
        "</center>\n",
        "\n",
        "---\n",
        "\n",
        "This project shows how to perform a mall customers segmentation using Machine Learning algorithms. This is the unsupervised clustering problem and three popular algorithms will be presented and compared: KMeans, Affinity Propagation and DBSCAN. There will be some further discussions about these algorithms alterations and their current state of developments/research. The main aim of this notebook is to cover the basics of clustering methods and touch some more advanced aspects as well.\n",
        "\n",
        "The notebook is divided into six main sections. At the end of the notebook, you will find also references I used during the preparation of this notebook. In order to increase readability some code is hidded (so, please unhide them to see the code).\n",
        "\n",
        "### SECTIONS:  \n",
        "1. [Introduction](#Intro)<br>  \n",
        "2. [Reading Data](#Reading_data)<br>  \n",
        "3. [Exploratory Data Analysis](#Exploratory_Data_Analysis)<br>\n",
        "   3.1 [Distributions](#Distributions)<br>\n",
        "   3.2 [Correlations](#Correlations)<br>\n",
        "4. [Clustering](#Clustering)<br>\n",
        "   4.1 [K-Means](#K-Means)<br>\n",
        "   &nbsp;&nbsp;&nbsp;&nbsp; 4.1.1 [Description](#K-Means_description)<br>\n",
        "   &nbsp;&nbsp;&nbsp;&nbsp; 4.1.2 [Use case - customers segmentation](#K-Means_use_case)<br>\n",
        "   4.2 [DBSCAN](#DBSCAN)<br>\n",
        "   &nbsp;&nbsp;&nbsp;&nbsp; 4.2.1 [Description](#DBSCAN_description)<br>\n",
        "   &nbsp;&nbsp;&nbsp;&nbsp; 4.2.2 [Use case - customers segmentation](#DBSCAN_use_case)<br>\n",
        "   4.3 [Affinity Propagation](#AF)<br>\n",
        "   &nbsp;&nbsp;&nbsp;&nbsp; 4.3.1 [Description](#AF_description)<br>\n",
        "   &nbsp;&nbsp;&nbsp;&nbsp; 4.3.2 [Use case - customers segmentation](#AF_use_case)<br>\n",
        "5. [Comparison and discussion](#Comparison_and_discussion)<br>\n",
        "6. [References](#References)<br>\n",
        "\n",
        "<a id='Intro'></a>\n",
        "## 1. Introduction  <a href='#Top' style=\"text-decoration: none;\">^</a><br>\n",
        "\n",
        "\n",
        "The main task of clustering is to discover „natural“ groups within an unlabelled dataset - this means that's an unsuprvised ML task. And it's an important one, as as it is used in many scientific, engineering and business domains. One of the most known application of clustering are:  \n",
        "* customers segmentation (for efficient marketing)\n",
        "* image segmentation\n",
        "* documents clusterisation.\n",
        "  \n",
        "There are many clustering algorithms which can be divided into two main types: hierarchical and partitional.\n",
        "\n",
        "* <u>Hierarchical</u> algorithms recursively split a dataset into a smaller subset until a subset contains only one item. This can be represented with a dendrogram which looks like a tree. It can be constructed from leaves to the roo(agglomerative approach) or from the root down to the leaves (divisive approach). In hierarchical clustering, you don’t have to specify the number of clusters but you have to define a termination condition for splitting/merging process. </li>     \n",
        "\n",
        "* <u>Partitional</u> algorithms divide a dataset into several subsets (clusters) based on a given criteria. For some algorithms number of clusters has to be defined a priori (e.g K-Means) and for some not (DBSCAN). Defining the number of clusters before running an algorithm often requires a specific domain knowledge which is often challenging (or even impossible) in many applications. This led to the development of many heuristics and simplified approaches helping analyst without domain knowledge to choose the appropriate number of clusters.</li>\n",
        "\n",
        "There is a vast number of clustering algorithms and currently, there is no single one that dominates other ones. Choosing the best one depends on the database itself, an application domain and client requirements and expectations.\n",
        "This notebook focuses on three partitional algorithms: K-Means, DBSCAN and Affinity Propagation. All are implemented in a well-known Python library: Scikit-Learn."
      ],
      "metadata": {
        "id": "5x1HOJ3CggvZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id='Reading_data'></a>\n",
        "## 2. Reading data <a href='#Top' style=\"text-decoration: none;\">^</a><br>\n",
        "\n",
        "In this section, raw data will be read, overviewed and checked if any cleaning is required."
      ],
      "metadata": {
        "id": "prFwoZ90ggvc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "print(\"pandas version: {}\".format(pd.__version__))\n",
        "print(\"numpy version: {}\".format(np.__version__))\n",
        "print(\"seaborn version: {}\".format(sns.__version__))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-24T15:06:01.519369Z",
          "iopub.execute_input": "2022-05-24T15:06:01.520109Z",
          "iopub.status.idle": "2022-05-24T15:06:01.527207Z",
          "shell.execute_reply.started": "2022-05-24T15:06:01.520045Z",
          "shell.execute_reply": "2022-05-24T15:06:01.526469Z"
        },
        "trusted": true,
        "id": "ed1JpwXqggvc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mall_data = pd.read_csv('../input/customer-segmentation-tutorial-in-python/Mall_Customers.csv')\n",
        "\n",
        "print('There are {} rows and {} columns in our dataset.'.format(mall_data.shape[0],mall_data.shape[1]))"
      ],
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "execution": {
          "iopub.status.busy": "2022-05-24T15:06:01.572375Z",
          "iopub.execute_input": "2022-05-24T15:06:01.572722Z",
          "iopub.status.idle": "2022-05-24T15:06:01.590668Z",
          "shell.execute_reply.started": "2022-05-24T15:06:01.572653Z",
          "shell.execute_reply": "2022-05-24T15:06:01.589596Z"
        },
        "trusted": true,
        "id": "9kWKICLtggvd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mall_data.sample(10)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-24T15:06:01.612473Z",
          "iopub.execute_input": "2022-05-24T15:06:01.613077Z",
          "iopub.status.idle": "2022-05-24T15:06:01.635141Z",
          "shell.execute_reply.started": "2022-05-24T15:06:01.613027Z",
          "shell.execute_reply": "2022-05-24T15:06:01.633552Z"
        },
        "trusted": true,
        "id": "xvexTvjBggve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mall_data.describe()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-24T15:06:01.652937Z",
          "iopub.execute_input": "2022-05-24T15:06:01.653533Z",
          "iopub.status.idle": "2022-05-24T15:06:01.686595Z",
          "shell.execute_reply.started": "2022-05-24T15:06:01.65348Z",
          "shell.execute_reply": "2022-05-24T15:06:01.685514Z"
        },
        "trusted": true,
        "id": "xLZPijhoggve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are 5 columns:\n",
        "* `Customer ID` - numerical - unique customer number - integer\n",
        "* `Gender` - categorical - binary (Male/Female)\n",
        "* `Age` - numerical - integer\n",
        "* `Annual Income (k$)` - numerical - integer\n",
        "* `Spending Score (1-100)` - numerical - integer\n",
        "\n",
        "There is one binary, categorical column: ```gender```. You may be tempted to one-hot encode it for the clustering. It is:\n",
        "* technically possible\n",
        "* theoretically not forbidden\n",
        "* practically not recommended\n",
        "\n",
        "However, it is not recommended and nicely explained on the [IBM support site](https://www.ibm.com/support/pages/clustering-binary-data-k-means-should-be-avoided)."
      ],
      "metadata": {
        "id": "7HdsUz6Sggvf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mall_data.describe()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-24T15:06:01.688777Z",
          "iopub.execute_input": "2022-05-24T15:06:01.68936Z",
          "iopub.status.idle": "2022-05-24T15:06:01.725236Z",
          "shell.execute_reply.started": "2022-05-24T15:06:01.689282Z",
          "shell.execute_reply": "2022-05-24T15:06:01.723817Z"
        },
        "trusted": true,
        "id": "x4YuJ1Rzggvf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mall_data.isnull().sum()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-24T15:06:01.728031Z",
          "iopub.execute_input": "2022-05-24T15:06:01.728767Z",
          "iopub.status.idle": "2022-05-24T15:06:01.739787Z",
          "shell.execute_reply.started": "2022-05-24T15:06:01.728519Z",
          "shell.execute_reply": "2022-05-24T15:06:01.737821Z"
        },
        "trusted": true,
        "id": "MG_gODS0ggvf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are no missing data. This simplifies the analysis but it is a very unlikely scenario in a real-life where analysts spend a significant amount of time cleaning their data before the core analysis is performed"
      ],
      "metadata": {
        "id": "wtQlx_5tggvg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id='Exploratory_Data_Analysis'></a>\n",
        "## 3. Exploratory Data Analysis<a href='#Top' style=\"text-decoration: none;\">^</a><br>\n",
        "\n",
        "This section contains a basic statistical investigation of a given database. It is a crucial point in any analysis as it allows for a better understanding of the underlying data. This part has two main sections: distributions and correlations."
      ],
      "metadata": {
        "id": "1JaXtdeJggvg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id='Distributions'></a>\n",
        "### 3.1 Distributions <a href='#Top' style=\"text-decoration: none;\">^</a><br>\n",
        "\n",
        "In this chapter distributions of numerical variables will be investigated in detail. Data will be stratified by gender - the only categorical variable."
      ],
      "metadata": {
        "id": "3jNa_avzggvg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "males_age = mall_data[mall_data['Gender']=='Male']['Age'] # subset with males age\n",
        "females_age = mall_data[mall_data['Gender']=='Female']['Age'] # subset with females age\n",
        "\n",
        "age_bins = range(15,75,5)\n",
        "\n",
        "# males histogram\n",
        "fig2, (ax1, ax2) = plt.subplots(1, 2, figsize=(12,5), sharey=True)\n",
        "sns.distplot(males_age, bins=age_bins, kde=False, color='#0066ff', ax=ax1, hist_kws=dict(edgecolor=\"k\", linewidth=2))\n",
        "ax1.set_xticks(age_bins)\n",
        "ax1.set_ylim(top=25)\n",
        "ax1.set_title('Males')\n",
        "ax1.set_ylabel('Count')\n",
        "ax1.text(45,23, \"TOTAL count: {}\".format(males_age.count()))\n",
        "ax1.text(45,22, \"Mean age: {:.1f}\".format(males_age.mean()))\n",
        "\n",
        "# females histogram\n",
        "sns.distplot(females_age, bins=age_bins, kde=False, color='#cc66ff', ax=ax2, hist_kws=dict(edgecolor=\"k\", linewidth=2))\n",
        "ax2.set_xticks(age_bins)\n",
        "ax2.set_title('Females')\n",
        "ax2.set_ylabel('Count')\n",
        "ax2.text(45,23, \"TOTAL count: {}\".format(females_age.count()))\n",
        "ax2.text(45,22, \"Mean age: {:.1f}\".format(females_age.mean()))\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-24T15:06:01.781701Z",
          "iopub.execute_input": "2022-05-24T15:06:01.782279Z",
          "iopub.status.idle": "2022-05-24T15:06:02.373888Z",
          "shell.execute_reply.started": "2022-05-24T15:06:01.78223Z",
          "shell.execute_reply": "2022-05-24T15:06:02.372029Z"
        },
        "trusted": true,
        "id": "svbZuiW0ggvg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Kolgomorov-Smirnov test p-value: {:.2f}'.format(stats.ks_2samp(males_age, females_age)[1]))"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2022-05-24T15:06:02.377115Z",
          "iopub.execute_input": "2022-05-24T15:06:02.377868Z",
          "iopub.status.idle": "2022-05-24T15:06:02.393695Z",
          "shell.execute_reply.started": "2022-05-24T15:06:02.377576Z",
          "shell.execute_reply": "2022-05-24T15:06:02.391772Z"
        },
        "trusted": true,
        "id": "rGGNBL6zggvh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The average age of male customers is lightly higher than female ones (39.8 versus 38.1). Distribution of male age is more uniform than females, where we can observe that the biggest age group is 30-35 years old. Kolgomorov-Smirnov test shows that the differences between these two groups are statistically insignificant."
      ],
      "metadata": {
        "id": "3tnvy3Zwggvh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def labeler(pct, allvals):\n",
        "    absolute = int(pct/100.*np.sum(allvals))\n",
        "    return \"{:.1f}%\\n({:d})\".format(pct, absolute)\n",
        "\n",
        "sizes = [males_age.count(),females_age.count()] # wedge sizes\n",
        "\n",
        "fig0, ax1 = plt.subplots(figsize=(6,6))\n",
        "wedges, texts, autotexts = ax1.pie(sizes,\n",
        "                                   autopct=lambda pct: labeler(pct, sizes),\n",
        "                                   radius=1,\n",
        "                                   colors=['#0066ff','#cc66ff'],\n",
        "                                   startangle=90,\n",
        "                                   textprops=dict(color=\"w\"),\n",
        "                                   wedgeprops=dict(width=0.7, edgecolor='w'))\n",
        "\n",
        "ax1.legend(wedges, ['male','female'],\n",
        "           loc='center right',\n",
        "           bbox_to_anchor=(0.7, 0, 0.5, 1))\n",
        "\n",
        "plt.text(0,0, 'TOTAL\\n{}'.format(mall_data['Age'].count()),\n",
        "         weight='bold', size=12, color='#52527a',\n",
        "         ha='center', va='center')\n",
        "\n",
        "plt.setp(autotexts, size=12, weight='bold')\n",
        "ax1.axis('equal')  # Equal aspect ratio\n",
        "plt.show()"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2022-05-24T15:06:02.396469Z",
          "iopub.execute_input": "2022-05-24T15:06:02.397285Z",
          "iopub.status.idle": "2022-05-24T15:06:02.683439Z",
          "shell.execute_reply.started": "2022-05-24T15:06:02.397212Z",
          "shell.execute_reply": "2022-05-24T15:06:02.682232Z"
        },
        "trusted": true,
        "id": "TcxzZLkpggvh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are slightly more female customers than male ones (112 vs. 87). Females are 56% of total customers."
      ],
      "metadata": {
        "id": "dLv7mgSGggvh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "males_income = mall_data[mall_data['Gender']=='Male']['Annual Income (k$)'] # subset with males income\n",
        "females_income = mall_data[mall_data['Gender']=='Female']['Annual Income (k$)'] # subset with females income\n",
        "\n",
        "my_bins = range(10,150,10)\n",
        "\n",
        "# males histogram\n",
        "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18,5))\n",
        "sns.distplot(males_income, bins=my_bins, kde=False, color='#0066ff', ax=ax1, hist_kws=dict(edgecolor=\"k\", linewidth=2))\n",
        "ax1.set_xticks(my_bins)\n",
        "ax1.set_yticks(range(0,24,2))\n",
        "ax1.set_ylim(0,22)\n",
        "ax1.set_title('Males')\n",
        "ax1.set_ylabel('Count')\n",
        "ax1.text(85,19, \"Mean income: {:.1f}k$\".format(males_income.mean()))\n",
        "ax1.text(85,18, \"Median income: {:.1f}k$\".format(males_income.median()))\n",
        "ax1.text(85,17, \"Std. deviation: {:.1f}k$\".format(males_income.std()))\n",
        "\n",
        "# females histogram\n",
        "sns.distplot(females_income, bins=my_bins, kde=False, color='#cc66ff', ax=ax2, hist_kws=dict(edgecolor=\"k\", linewidth=2))\n",
        "ax2.set_xticks(my_bins)\n",
        "ax2.set_yticks(range(0,24,2))\n",
        "ax2.set_ylim(0,22)\n",
        "ax2.set_title('Females')\n",
        "ax2.set_ylabel('Count')\n",
        "ax2.text(85,19, \"Mean income: {:.1f}k$\".format(females_income.mean()))\n",
        "ax2.text(85,18, \"Median income: {:.1f}k$\".format(females_income.median()))\n",
        "ax2.text(85,17, \"Std. deviation: {:.1f}k$\".format(females_income.std()))\n",
        "\n",
        "# boxplot\n",
        "sns.boxplot(x='Gender', y='Annual Income (k$)', data=mall_data, ax=ax3)\n",
        "ax3.set_title('Boxplot of annual income')\n",
        "plt.show()"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2022-05-24T15:06:02.685388Z",
          "iopub.execute_input": "2022-05-24T15:06:02.686073Z",
          "iopub.status.idle": "2022-05-24T15:06:03.606113Z",
          "shell.execute_reply.started": "2022-05-24T15:06:02.686001Z",
          "shell.execute_reply": "2022-05-24T15:06:03.604868Z"
        },
        "trusted": true,
        "id": "G9tx-RqPggvh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Kolgomorov-Smirnov test p-value: {:.2f}'.format(stats.ks_2samp(males_income, females_income)[1]))"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2022-05-24T15:06:03.612284Z",
          "iopub.execute_input": "2022-05-24T15:06:03.613424Z",
          "iopub.status.idle": "2022-05-24T15:06:03.628314Z",
          "shell.execute_reply.started": "2022-05-24T15:06:03.613305Z",
          "shell.execute_reply": "2022-05-24T15:06:03.626198Z"
        },
        "trusted": true,
        "id": "N_UCF9clggvi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mean income of males is higher than females (62.2 k\\\\$ vs. 59.2k\\\\$). Also median income of male customers (62.5k\\\\$) is higher thn female ones (60k\\\\$). Standard deviation is similar for both groups. There is one outlier in male group with an annual income of about 140k\\\\$. K-S test shows that these two groups are not statistically different."
      ],
      "metadata": {
        "id": "bjxEha_8ggvi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "males_spending = mall_data[mall_data['Gender']=='Male']['Spending Score (1-100)'] # subset with males age\n",
        "females_spending = mall_data[mall_data['Gender']=='Female']['Spending Score (1-100)'] # subset with females age\n",
        "\n",
        "spending_bins = range(0,105,5)\n",
        "\n",
        "# males histogram\n",
        "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18,5))\n",
        "sns.distplot(males_spending, bins=spending_bins, kde=False, color='#0066ff', ax=ax1, hist_kws=dict(edgecolor=\"k\", linewidth=2))\n",
        "ax1.set_xticks(spending_bins)\n",
        "ax1.set_xlim(0,100)\n",
        "ax1.set_yticks(range(0,17,1))\n",
        "ax1.set_ylim(0,16)\n",
        "ax1.set_title('Males')\n",
        "ax1.set_ylabel('Count')\n",
        "ax1.text(50,15, \"Mean spending score: {:.1f}\".format(males_spending.mean()))\n",
        "ax1.text(50,14, \"Median spending score: {:.1f}\".format(males_spending.median()))\n",
        "ax1.text(50,13, \"Std. deviation score: {:.1f}\".format(males_spending.std()))\n",
        "\n",
        "# females histogram\n",
        "sns.distplot(females_spending, bins=spending_bins, kde=False, color='#cc66ff', ax=ax2, hist_kws=dict(edgecolor=\"k\", linewidth=2))\n",
        "ax2.set_xticks(spending_bins)\n",
        "ax2.set_xlim(0,100)\n",
        "ax2.set_yticks(range(0,17,1))\n",
        "ax2.set_ylim(0,16)\n",
        "ax2.set_title('Females')\n",
        "ax2.set_ylabel('Count')\n",
        "ax2.text(50,15, \"Mean spending score: {:.1f}\".format(females_spending.mean()))\n",
        "ax2.text(50,14, \"Median spending score: {:.1f}\".format(females_spending.median()))\n",
        "ax2.text(50,13, \"Std. deviation score: {:.1f}\".format(females_spending.std()))\n",
        "\n",
        "# boxplot\n",
        "sns.boxplot(x='Gender', y='Spending Score (1-100)', data=mall_data, ax=ax3)\n",
        "ax3.set_title('Boxplot of spending score')\n",
        "plt.show()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2022-05-24T15:06:03.632724Z",
          "iopub.execute_input": "2022-05-24T15:06:03.633016Z",
          "iopub.status.idle": "2022-05-24T15:06:04.781084Z",
          "shell.execute_reply.started": "2022-05-24T15:06:03.632971Z",
          "shell.execute_reply": "2022-05-24T15:06:04.779381Z"
        },
        "trusted": true,
        "id": "_1NCMuDgggvi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Kolgomorov-Smirnov test p-value: {:.2f}'.format(stats.ks_2samp(males_spending, females_spending)[1]))"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2022-05-24T15:06:04.783436Z",
          "iopub.execute_input": "2022-05-24T15:06:04.784403Z",
          "iopub.status.idle": "2022-05-24T15:06:04.798359Z",
          "shell.execute_reply.started": "2022-05-24T15:06:04.784056Z",
          "shell.execute_reply": "2022-05-24T15:06:04.796941Z"
        },
        "trusted": true,
        "id": "qtGzFfIwggvi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A mean spending score for women (51.5) is higher than men (48.5). The K-S test p-value indicates that there is no evidence to reject the null-hypothesis, however the evidence is not so strong as in previous comparisons.\n",
        "Next I will calculate median income for  all age groups."
      ],
      "metadata": {
        "id": "J27f_Hbnggvi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "medians_by_age_group = mall_data.groupby([\"Gender\",pd.cut(mall_data['Age'], age_bins)]).median()\n",
        "medians_by_age_group.index = medians_by_age_group.index.set_names(['Gender', 'Age_group'])\n",
        "medians_by_age_group.reset_index(inplace=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-24T15:06:04.800437Z",
          "iopub.execute_input": "2022-05-24T15:06:04.801153Z",
          "iopub.status.idle": "2022-05-24T15:06:04.836762Z",
          "shell.execute_reply.started": "2022-05-24T15:06:04.801083Z",
          "shell.execute_reply": "2022-05-24T15:06:04.835683Z"
        },
        "trusted": true,
        "id": "x5AGh5nCggvi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(12,5))\n",
        "sns.barplot(x='Age_group', y='Annual Income (k$)', hue='Gender', data=medians_by_age_group,\n",
        "            palette=['#cc66ff','#0066ff'],\n",
        "            alpha=0.7,edgecolor='k',\n",
        "            ax=ax)\n",
        "ax.set_title('Median annual income of male and female customers')\n",
        "ax.set_xlabel('Age group')\n",
        "plt.show()"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2022-05-24T15:06:04.838115Z",
          "iopub.execute_input": "2022-05-24T15:06:04.838996Z",
          "iopub.status.idle": "2022-05-24T15:06:05.333213Z",
          "shell.execute_reply.started": "2022-05-24T15:06:04.838939Z",
          "shell.execute_reply": "2022-05-24T15:06:05.331972Z"
        },
        "trusted": true,
        "id": "P25fcfZKggvi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A bar chart above shows that the most wealthy customers are in age of 25-45 years old. The biggest difference between women and men is visible in  age groups 25-30 (male more rich) and 50-55 (female more rich)."
      ],
      "metadata": {
        "id": "sI99qpYXggvi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id='Correlations'></a>\n",
        "### 3.2 Correlations<a href='#Top' style=\"text-decoration: none;\">^</a><br>\n",
        "This chapter investigates correlations between numerical variables."
      ],
      "metadata": {
        "id": "vms6j3G7ggvj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import pearsonr\n",
        "\n",
        "# calculating Pearson's correlation\n",
        "corr, _ = pearsonr(mall_data['Age'], mall_data['Spending Score (1-100)'])\n",
        "\n",
        "jp = (sns.jointplot('Age', 'Spending Score (1-100)', data=mall_data,\n",
        "                    kind='reg')).plot_joint(sns.kdeplot, zorder=0, n_levels=6)\n",
        "\n",
        "plt.text(0,120, 'Pearson: {:.2f}'.format(corr))\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-24T15:06:05.335596Z",
          "iopub.execute_input": "2022-05-24T15:06:05.336054Z",
          "iopub.status.idle": "2022-05-24T15:06:07.132455Z",
          "shell.execute_reply.started": "2022-05-24T15:06:05.335977Z",
          "shell.execute_reply": "2022-05-24T15:06:07.131388Z"
        },
        "trusted": true,
        "id": "dtbIaM9Zggvj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculating Pearson's correlations\n",
        "corr1, _ = pearsonr(males_age.values, males_income.values)\n",
        "corr2, _ = pearsonr(females_age.values, females_income.values)\n",
        "\n",
        "sns.lmplot('Age', 'Annual Income (k$)', data=mall_data, hue='Gender',\n",
        "          aspect=1.5)\n",
        "\n",
        "plt.text(15,87, 'Pearson: {:.2f}'.format(corr1), color='blue')\n",
        "plt.text(65,80, 'Pearson: {:.2f}'.format(corr2), color='orange')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-24T15:06:07.133882Z",
          "iopub.execute_input": "2022-05-24T15:06:07.134222Z",
          "iopub.status.idle": "2022-05-24T15:06:07.85565Z",
          "shell.execute_reply.started": "2022-05-24T15:06:07.134153Z",
          "shell.execute_reply": "2022-05-24T15:06:07.854518Z"
        },
        "trusted": true,
        "id": "H0nBXXJpggvj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is a negligible correlation between age and annual income of customers for both sex groups."
      ],
      "metadata": {
        "id": "NZ7Wl3Ygggvj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# calculating Pearson's correlations\n",
        "corr1, _ = pearsonr(males_age.values, males_spending.values)\n",
        "corr2, _ = pearsonr(females_age.values, females_spending.values)\n",
        "\n",
        "sns.lmplot('Age', 'Spending Score (1-100)', data=mall_data, hue='Gender',\n",
        "          aspect=1.5)\n",
        "\n",
        "plt.text(65,65, 'Pearson: {:.2f}'.format(corr1), color='blue')\n",
        "plt.text(13,83, 'Pearson: {:.2f}'.format(corr2), color='#d97900')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2022-05-24T15:06:07.857209Z",
          "iopub.execute_input": "2022-05-24T15:06:07.857581Z",
          "iopub.status.idle": "2022-05-24T15:06:08.569032Z",
          "shell.execute_reply.started": "2022-05-24T15:06:07.85752Z",
          "shell.execute_reply": "2022-05-24T15:06:08.568088Z"
        },
        "trusted": true,
        "id": "9RGLtxEPggvj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are week negative correlations (<0.5) between age and spending score for both sex groups."
      ],
      "metadata": {
        "id": "-FkPPFMOggvj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# calculating Pearson's correlations\n",
        "corr1, _ = pearsonr(males_income.values, males_spending.values)\n",
        "corr2, _ = pearsonr(females_income.values, females_spending.values)\n",
        "\n",
        "sns.lmplot('Annual Income (k$)', 'Spending Score (1-100)', data=mall_data, hue='Gender',\n",
        "          aspect=1.5)\n",
        "\n",
        "plt.text(130,23, 'Pearson: {:.2f}'.format(corr1), color='blue')\n",
        "plt.text(130,77, 'Pearson: {:.2f}'.format(corr2), color='#d97900')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2022-05-24T15:06:08.570623Z",
          "iopub.execute_input": "2022-05-24T15:06:08.571172Z",
          "iopub.status.idle": "2022-05-24T15:06:09.292433Z",
          "shell.execute_reply.started": "2022-05-24T15:06:08.571111Z",
          "shell.execute_reply": "2022-05-24T15:06:09.291227Z"
        },
        "trusted": true,
        "id": "y-c9aSZaggvj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is a negligible correlation between annual income and spending score of customers for both sex groups."
      ],
      "metadata": {
        "id": "6VJ9StMRggvk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id='Clustering'></a>\n",
        "## 4. Clustering<a href='#Top' style=\"text-decoration: none;\">^</a><br>  \n",
        "\n",
        "This section of the notebook describes and demonstrates how to use three clustering algorithms:  \n",
        "* K-Means\n",
        "* Density-Based Spatial Clustering of Applications with Noise (DBSCAN)\n",
        "* Affinity Propagation.\n",
        "\n",
        "I will not standarize data for this case. When you should or should do it is nicely explained [here on Data Science Stack Exchange](https://datascience.stackexchange.com/questions/6715/is-it-necessary-to-standardize-your-data-before-clustering)."
      ],
      "metadata": {
        "id": "g_HRJDZ0ggvk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id='K-Means'></a>\n",
        "### 4.1 K-Means<a href='#Top' style=\"text-decoration: none;\">^</a><br>  \n",
        "\n",
        "This chapter focuses on a very popular K-Means algorithm being taught in most machine learning courses. The chapter contains two sub-chapters: description of the algorithm and a use case (mall customers segmentation).\n",
        "\n",
        "<a id='K-Means_description'></a>\n",
        "### 4.1.1 Description<a href='#Top' style=\"text-decoration: none;\">^</a><br>  \n",
        "\n",
        "The most well-known partitional clustering algorithm is K-Means. It was independently developed in many places in the 50s and 60s and gained great popularity because of its ease of implementation, simplicity and many empirical successes (e.g. in business, medicine and science).  \n",
        "\n",
        "There are 3 main steps in K-Means algorithm (known also as Lloyd’s algorithm):\n",
        "<ol>\n",
        "    <li>Split samples into initial groups by using seed points. The nearest samples to these seed point will create initial clusters.</li>\n",
        "    <li>Calculate samples distances to groups’ central points (centroids) and assign the nearest samples to their cluster.</li>\n",
        "    <li>The third step is to calculate newly created (updated) cluster centroids.</li>\n",
        "</ol>\n",
        "Then repeat steps 2 and 3 until the algorithm converges.<br>  \n",
        "\n",
        "As mentioned earlier the goal of K-Means is to minimise the objective function (inertia) over all clusters. The objective function is defined as:"
      ],
      "metadata": {
        "id": "RVntDwj-ggvk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Inertia.jpg](attachment:Inertia.jpg)"
      ],
      "metadata": {
        "id": "zlGy_sC4ggvk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is known as NP-hard problem, meaning this is a greedy algorithm and converges to the local minimum. The computational cost of Lloyd’s K-Means algorithm is O(kn), where k is a number of clusters and n is a number of samples. This is not bad when compared with other clustering algorithms. Despite converging usually to a local minimum, K-means is relatively fast and when groups are well isolated from each other it is likely that it converges to the global minimum. Because the result of clusterisation depends on the initialisation criteria it is common to run the analysis for various initialisation points and choose the one with minimum resultant inertia. There are some improvements to the algorithm solving problem of the local minima. One, exemplary, improvement is to use enhanced Firefly Algorithms about which you can read [here](https://www.sciencedirect.com/science/article/pii/S1568494619305447).<br><br>\n",
        "\n",
        "In general, a user of the K-Means algorithm is required to define three main parameters:<br>  \n",
        "\n",
        "1. **Initialisation criteria**  \n",
        "    In scikit-learn, a clever initialisation scheme is implemented: “k-means++” proposed by Arthur and Vassilvitskii. It creates initial centroids generally distant from each other increasing probability of obtaining better results. There is also a possibility to use a random point’s generator. There are ongoing efforts to create the most efficient seeding method for K-Means algorithm, one of them is based on Independent Component Analysis and you can read more about it [here](http://www.ymd.nii.ac.jp/lab/publication/conference/2010/IWI-Onoda-2010.pdf).\n",
        "\n",
        "2. **Number of clusters**  \n",
        "    Selecting a number of clusters is the most challenging part of setting this algorithm. There are no hard mathematical criteria for this and many heuristic/simplified approaches have been developed. One of the simplest and the most popular one is the elbow method shown in this analysis. Additionaly a silhouette score will be used as well.\n",
        "    There are also other, often advanced, options for choosing the optimal number of clusters (however, not used in this notebook and not implemented in sklearn), e.g.:\n",
        "    \n",
        "\n",
        "* Minimum Message Length (MML) - [more](https://en.wikipedia.org/wiki/Minimum_message_length)\n",
        "* Minimum Description Length (MDL) - [more](https://en.wikipedia.org/wiki/Minimum_description_length)\n",
        "* Bayes Information Criterion (BIC) - [more](https://en.wikipedia.org/wiki/Bayesian_information_criterion)\n",
        "* Akaike Information Criterion (AIC) - [more](https://en.wikipedia.org/wiki/Akaike_information_criterion)\n",
        "* Dirichlet Process\n",
        "* Gap statistics\n",
        "\n",
        "\n",
        "3. **A distance metric (not required in scikit learn implementation)**  \n",
        "    There are various options to calculate the distance between points. The most popular one is simply the Euclidean metric and it is the one implemented in scikit-learn. It is often called spherical k-means model. It has a drawback that it finds spherical-like groups only and tends to become inflated in highly multi-dimensional analyses (“curse of dimensionality”). There are other options but not implemented in scikit-learn, e.g.:\n",
        "    \n",
        "    \n",
        "* Mahalonobis distance (high computiational cost)\n",
        "* Itakura-Saito distance\n",
        "* L1 distance\n",
        "* Cosine distance\n",
        "* Bregman distance\n",
        "\n",
        "\n",
        "There are numerous ongoing researches and variations proposed to K-Means, e.g.:  \n",
        "* K-Medoid where the centroid is defined as the most centrally located object)\n",
        "* K-Median where the centroid is calculated using median instead of a mean,\n",
        "* Fuzzy C-means model\n",
        "\n",
        "Some take-aways about K-Means:\n",
        "\n",
        "1. Euclidean distances are used\n",
        "2. Number of clusters has to be defined for the algorithm\n",
        "3. Centroid is calculated using mean distance to cluster members\n",
        "4. Clusters are assumed isotropic and convex\n",
        "5. Stochastic algorithm – results depend on the initialisation criteria\n",
        "6. Creates groups of equal variance (minimises inertia)\n",
        "7. Prone to the “curse of dimensionality”\n",
        "8. Can be run in parallel – so it scales well"
      ],
      "metadata": {
        "id": "cwj5yEScggvk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id='K-Means_use_case'></a>\n",
        "### 4.1.2 Use case - customers segmentation<a href='#Top' style=\"text-decoration: none;\">^</a><br>  \n",
        "\n",
        "The very first step in a clustering analysis is importing K-Means from the sklearn library."
      ],
      "metadata": {
        "id": "jV7nGsIkggvl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-24T15:06:09.29467Z",
          "iopub.execute_input": "2022-05-24T15:06:09.295223Z",
          "iopub.status.idle": "2022-05-24T15:06:09.300969Z",
          "shell.execute_reply.started": "2022-05-24T15:06:09.295158Z",
          "shell.execute_reply": "2022-05-24T15:06:09.299562Z"
        },
        "trusted": true,
        "id": "HfcZgwS8ggvl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For clustering only numeric columns are used. As mentioned at the beginning the binary variable `gender` will not be used here."
      ],
      "metadata": {
        "id": "AvVKORh8ggvl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_numerics = mall_data[['Age', 'Annual Income (k$)', 'Spending Score (1-100)']] # subset with numeric variables only"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-24T15:06:09.30282Z",
          "iopub.execute_input": "2022-05-24T15:06:09.3035Z",
          "iopub.status.idle": "2022-05-24T15:06:09.319456Z",
          "shell.execute_reply.started": "2022-05-24T15:06:09.303434Z",
          "shell.execute_reply": "2022-05-24T15:06:09.317121Z"
        },
        "trusted": true,
        "id": "F_IM-_Acggvl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to find an appropriate number of clusters, the elbow method will be used. In this method for this case, the inertia for a number of clusters between 2 and 10 will be calculated. The rule is to choose the number of clusters where you see a kink or \"an elbow\" in the graph."
      ],
      "metadata": {
        "id": "e32ReiYPggvm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from yellowbrick.cluster import KElbowVisualizer\n",
        "\n",
        "model = KMeans(random_state=1)\n",
        "visualizer = KElbowVisualizer(model, k=(2,10))\n",
        "\n",
        "visualizer.fit(X_numerics)\n",
        "visualizer.show()\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-24T15:06:09.321849Z",
          "iopub.execute_input": "2022-05-24T15:06:09.323434Z",
          "iopub.status.idle": "2022-05-24T15:06:10.217633Z",
          "shell.execute_reply.started": "2022-05-24T15:06:09.322216Z",
          "shell.execute_reply": "2022-05-24T15:06:10.216581Z"
        },
        "trusted": true,
        "id": "6E6a5J2Lggvm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The graph above shows the reduction of a distortion score as the number of clusters increases. However, there is no clear \"elbow\" visible. The underlying algorithm suggests 5 clusters. A choice of 5 or 6 clusters seems to be fair.\n",
        "\n",
        "Another way to choose the best number of clusters is to plot the silhuette score in a function of number of clusters. Let's see the results."
      ],
      "metadata": {
        "id": "CcYQATyFggvm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = KMeans(random_state=1)\n",
        "visualizer = KElbowVisualizer(model, k=(2,10), metric='silhouette')\n",
        "\n",
        "visualizer.fit(X_numerics)\n",
        "visualizer.show()\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-24T15:06:10.219162Z",
          "iopub.execute_input": "2022-05-24T15:06:10.219682Z",
          "iopub.status.idle": "2022-05-24T15:06:10.980001Z",
          "shell.execute_reply.started": "2022-05-24T15:06:10.219623Z",
          "shell.execute_reply": "2022-05-24T15:06:10.979296Z"
        },
        "trusted": true,
        "id": "9hRTq1tIggvm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Silhouette score method indicates the best options would be 5 or 6 clusters. Let's compare both."
      ],
      "metadata": {
        "id": "s7DqF5B-ggvm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<u>**5 CLUSTERS**</u>"
      ],
      "metadata": {
        "id": "NoW5qHJEggvm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "KM_5_clusters = KMeans(n_clusters=5, init='k-means++').fit(X_numerics) # initialise and fit K-Means model\n",
        "\n",
        "KM5_clustered = X_numerics.copy()\n",
        "KM5_clustered.loc[:,'Cluster'] = KM_5_clusters.labels_ # append labels to points"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-24T15:06:10.981455Z",
          "iopub.execute_input": "2022-05-24T15:06:10.981982Z",
          "iopub.status.idle": "2022-05-24T15:06:11.035243Z",
          "shell.execute_reply.started": "2022-05-24T15:06:10.981923Z",
          "shell.execute_reply": "2022-05-24T15:06:11.034531Z"
        },
        "trusted": true,
        "id": "MzeA2qtjggvn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig1, (axes) = plt.subplots(1,2,figsize=(12,5))\n",
        "\n",
        "\n",
        "scat_1 = sns.scatterplot('Annual Income (k$)', 'Spending Score (1-100)', data=KM5_clustered,\n",
        "                hue='Cluster', ax=axes[0], palette='Set1', legend='full')\n",
        "\n",
        "sns.scatterplot('Age', 'Spending Score (1-100)', data=KM5_clustered,\n",
        "                hue='Cluster', palette='Set1', ax=axes[1], legend='full')\n",
        "\n",
        "axes[0].scatter(KM_5_clusters.cluster_centers_[:,1],KM_5_clusters.cluster_centers_[:,2], marker='s', s=40, c=\"blue\")\n",
        "axes[1].scatter(KM_5_clusters.cluster_centers_[:,0],KM_5_clusters.cluster_centers_[:,2], marker='s', s=40, c=\"blue\")\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-24T15:06:11.039299Z",
          "iopub.execute_input": "2022-05-24T15:06:11.039897Z",
          "iopub.status.idle": "2022-05-24T15:06:11.581807Z",
          "shell.execute_reply.started": "2022-05-24T15:06:11.039849Z",
          "shell.execute_reply": "2022-05-24T15:06:11.580793Z"
        },
        "trusted": true,
        "id": "qVgRkJVxggvn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "K-Means algorithm generated the following 5 clusters:\n",
        "* clients with **low** annual income and **high** spending score\n",
        "* clients with **medium** annual income and **medium** spending score\n",
        "* clients with **high** annual income and **low** spending score\n",
        "* clients with **high** annual income and **high** spending score\n",
        "* clients with **low** annual income and **low** spending score\n",
        "\n",
        "There are no distinct groups is terms of customers age."
      ],
      "metadata": {
        "id": "h9g4zmJcggvn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sizes of the clusters:"
      ],
      "metadata": {
        "id": "tQLfJIskggvn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "KM_clust_sizes = KM5_clustered.groupby('Cluster').size().to_frame()\n",
        "KM_clust_sizes.columns = [\"KM_size\"]\n",
        "KM_clust_sizes"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-24T15:06:11.583571Z",
          "iopub.execute_input": "2022-05-24T15:06:11.584175Z",
          "iopub.status.idle": "2022-05-24T15:06:11.599694Z",
          "shell.execute_reply.started": "2022-05-24T15:06:11.584095Z",
          "shell.execute_reply": "2022-05-24T15:06:11.598673Z"
        },
        "trusted": true,
        "id": "LXtw9-qkggvn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The biggest cluster is a cluster number 1 with 79 observations (\"medium-medium\" clients). There are two the smallest ones each containing 23 observations (cluster 3 \"high-high\" and cluster 0 \"low-high\" clients). Below there is a 3D projection of 5 generated clusters. It is not very helpful in terms of a visualisation in a static mode but if you run the code in an interactive environment (e.g. Spyder) you can rotate it!"
      ],
      "metadata": {
        "id": "dcz0v4soggvn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "fig = plt.figure(figsize=(7, 7))\n",
        "ax = Axes3D(fig, rect=[0, 0, .99, 1], elev=20, azim=210)\n",
        "ax.scatter(KM5_clustered['Age'],\n",
        "           KM5_clustered['Annual Income (k$)'],\n",
        "           KM5_clustered['Spending Score (1-100)'],\n",
        "           c=KM5_clustered['Cluster'],\n",
        "           s=35, edgecolor='k', cmap=plt.cm.Set1)\n",
        "\n",
        "ax.w_xaxis.set_ticklabels([])\n",
        "ax.w_yaxis.set_ticklabels([])\n",
        "ax.w_zaxis.set_ticklabels([])\n",
        "ax.set_xlabel('Age')\n",
        "ax.set_ylabel('Annual Income (k$)')\n",
        "ax.set_zlabel('Spending Score (1-100)')\n",
        "ax.set_title('3D view of K-Means 5 clusters')\n",
        "ax.dist = 12\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2022-05-24T15:06:11.601497Z",
          "iopub.execute_input": "2022-05-24T15:06:11.602183Z",
          "iopub.status.idle": "2022-05-24T15:06:11.890396Z",
          "shell.execute_reply.started": "2022-05-24T15:06:11.602121Z",
          "shell.execute_reply": "2022-05-24T15:06:11.889607Z"
        },
        "trusted": true,
        "id": "MNwsBtylggvo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below a Plotly version:"
      ],
      "metadata": {
        "id": "nd6CWj2rggvo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly as py\n",
        "import plotly.graph_objs as go\n",
        "\n",
        "def tracer(db, n, name):\n",
        "    '''\n",
        "    This function returns trace object for Plotly\n",
        "    '''\n",
        "    return go.Scatter3d(\n",
        "        x = db[db['Cluster']==n]['Age'],\n",
        "        y = db[db['Cluster']==n]['Spending Score (1-100)'],\n",
        "        z = db[db['Cluster']==n]['Annual Income (k$)'],\n",
        "        mode = 'markers',\n",
        "        name = name,\n",
        "        marker = dict(\n",
        "            size = 5\n",
        "        )\n",
        "     )\n",
        "\n",
        "trace0 = tracer(KM5_clustered, 0, 'Cluster 0')\n",
        "trace1 = tracer(KM5_clustered, 1, 'Cluster 1')\n",
        "trace2 = tracer(KM5_clustered, 2, 'Cluster 2')\n",
        "trace3 = tracer(KM5_clustered, 3, 'Cluster 3')\n",
        "trace4 = tracer(KM5_clustered, 4, 'Cluster 4')\n",
        "\n",
        "data = [trace0, trace1, trace2, trace3, trace4]\n",
        "\n",
        "layout = go.Layout(\n",
        "    title = 'Clusters by K-Means',\n",
        "    scene = dict(\n",
        "            xaxis = dict(title = 'Age'),\n",
        "            yaxis = dict(title = 'Spending Score'),\n",
        "            zaxis = dict(title = 'Annual Income')\n",
        "        )\n",
        ")\n",
        "\n",
        "fig = go.Figure(data=data, layout=layout)\n",
        "py.offline.iplot(fig)"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2022-05-24T15:06:11.891767Z",
          "iopub.execute_input": "2022-05-24T15:06:11.892324Z",
          "iopub.status.idle": "2022-05-24T15:06:15.775633Z",
          "shell.execute_reply.started": "2022-05-24T15:06:11.892268Z",
          "shell.execute_reply": "2022-05-24T15:06:15.774696Z"
        },
        "trusted": true,
        "id": "bw8pV-zrggvo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To check the quality of each cluster we can examine the Silhuette plot."
      ],
      "metadata": {
        "id": "tl-nYbEIggvo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from yellowbrick.cluster import SilhouetteVisualizer\n",
        "model = KMeans(n_clusters=5, random_state=0)\n",
        "visualizer = SilhouetteVisualizer(model, colors='yellowbrick')\n",
        "visualizer.fit(X_numerics)\n",
        "visualizer.show()\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-24T15:06:15.777138Z",
          "iopub.execute_input": "2022-05-24T15:06:15.777419Z",
          "iopub.status.idle": "2022-05-24T15:06:16.186776Z",
          "shell.execute_reply.started": "2022-05-24T15:06:15.777367Z",
          "shell.execute_reply": "2022-05-24T15:06:16.185561Z"
        },
        "trusted": true,
        "id": "9Qm_Lu7Vggvo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<u>**6 CLUSTERS**</u>"
      ],
      "metadata": {
        "id": "h2cxGiaMggvp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "KM_6_clusters = KMeans(n_clusters=6, init='k-means++').fit(X_numerics) # initialise and fit K-Means model\n",
        "\n",
        "KM6_clustered = X_numerics.copy()\n",
        "KM6_clustered.loc[:,'Cluster'] = KM_6_clusters.labels_ # append labels to points"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2022-05-24T15:06:16.189014Z",
          "iopub.execute_input": "2022-05-24T15:06:16.189926Z",
          "iopub.status.idle": "2022-05-24T15:06:16.245894Z",
          "shell.execute_reply.started": "2022-05-24T15:06:16.189848Z",
          "shell.execute_reply": "2022-05-24T15:06:16.244981Z"
        },
        "trusted": true,
        "id": "TtrWuUqBggvp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig11, (axes) = plt.subplots(1,2,figsize=(12,5))\n",
        "\n",
        "sns.scatterplot('Annual Income (k$)', 'Spending Score (1-100)', data=KM6_clustered,\n",
        "                hue='Cluster', ax=axes[0], palette='Set1', legend='full')\n",
        "\n",
        "sns.scatterplot('Age', 'Spending Score (1-100)', data=KM6_clustered,\n",
        "                hue='Cluster', palette='Set1', ax=axes[1], legend='full')\n",
        "\n",
        "# plotting centroids\n",
        "axes[0].scatter(KM_6_clusters.cluster_centers_[:,1], KM_6_clusters.cluster_centers_[:,2], marker='s', s=40, c=\"blue\")\n",
        "axes[1].scatter(KM_6_clusters.cluster_centers_[:,0], KM_6_clusters.cluster_centers_[:,2], marker='s', s=40, c=\"blue\")\n",
        "plt.show()"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2022-05-24T15:06:16.247578Z",
          "iopub.execute_input": "2022-05-24T15:06:16.248278Z",
          "iopub.status.idle": "2022-05-24T15:06:17.090188Z",
          "shell.execute_reply.started": "2022-05-24T15:06:16.248202Z",
          "shell.execute_reply": "2022-05-24T15:06:17.089211Z"
        },
        "trusted": true,
        "id": "6Fa24uZ_ggvp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "K-Means algorithm generated the following 6 clusters:\n",
        "<ol start=\"0\">\n",
        "    <li>younger clients with **medium** annual and **medium** spending score</li>\n",
        "    <li>clients with **high** annual income and **low** spending score</li>\n",
        "    <li>younger clients with **medium** annual and **medium** spending score</li>\n",
        "    <li>clients with **high** annual income and **high** spending score</li>\n",
        "    <li>clients with **low** annual income and **low** spending score</li>\n",
        "    <li>clients with **low** annual income and **high** spending score</li>\n",
        "</ol>\n",
        "\n",
        "There are no distinct groups is terms of customers age."
      ],
      "metadata": {
        "id": "j1WFGBsvggvp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "KM6_clust_sizes = KM6_clustered.groupby('Cluster').size().to_frame()\n",
        "KM6_clust_sizes.columns = [\"KM_size\"]\n",
        "KM6_clust_sizes"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-24T15:06:17.092114Z",
          "iopub.execute_input": "2022-05-24T15:06:17.092509Z",
          "iopub.status.idle": "2022-05-24T15:06:17.109386Z",
          "shell.execute_reply.started": "2022-05-24T15:06:17.092439Z",
          "shell.execute_reply": "2022-05-24T15:06:17.107925Z"
        },
        "trusted": true,
        "id": "FY7d4cGlggvp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotly interactive 3D plot\n",
        "\n",
        "trace0 = tracer(KM6_clustered, 0, 'Cluster 0')\n",
        "trace1 = tracer(KM6_clustered, 1, 'Cluster 1')\n",
        "trace2 = tracer(KM6_clustered, 2, 'Cluster 2')\n",
        "trace3 = tracer(KM6_clustered, 3, 'Cluster 3')\n",
        "trace4 = tracer(KM6_clustered, 4, 'Cluster 4')\n",
        "trace5 = tracer(KM6_clustered, 5, 'Cluster 5')\n",
        "\n",
        "data = [trace0, trace1, trace2, trace3, trace4, trace5]\n",
        "\n",
        "layout = go.Layout(\n",
        "    title = 'Clusters by K-Means',\n",
        "    scene = dict(\n",
        "            xaxis = dict(title = 'Age'),\n",
        "            yaxis = dict(title = 'Spending Score'),\n",
        "            zaxis = dict(title = 'Annual Income')\n",
        "        )\n",
        ")\n",
        "\n",
        "fig = go.Figure(data=data, layout=layout)\n",
        "py.offline.iplot(fig)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-24T15:06:17.110952Z",
          "iopub.execute_input": "2022-05-24T15:06:17.111509Z",
          "iopub.status.idle": "2022-05-24T15:06:17.615847Z",
          "shell.execute_reply.started": "2022-05-24T15:06:17.111175Z",
          "shell.execute_reply": "2022-05-24T15:06:17.614671Z"
        },
        "trusted": true,
        "id": "mxCtKmpQggvp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = KMeans(n_clusters=6, random_state=0)\n",
        "visualizer = SilhouetteVisualizer(model, colors='yellowbrick')\n",
        "visualizer.fit(X_numerics)\n",
        "visualizer.show()\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-24T15:06:17.617498Z",
          "iopub.execute_input": "2022-05-24T15:06:17.61795Z",
          "iopub.status.idle": "2022-05-24T15:06:18.04249Z",
          "shell.execute_reply.started": "2022-05-24T15:06:17.617873Z",
          "shell.execute_reply": "2022-05-24T15:06:18.040664Z"
        },
        "trusted": true,
        "id": "qrl6Nteiggvq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id='DBSCAN'></a>\n",
        "### 4.2 DBSCAN<a href='#Top' style=\"text-decoration: none;\">^</a><br>  \n",
        "\n",
        "This chapter describes how DBSCAN (Density-Based Spatial Clustering of Applications with Noise) works and shows its implementation to the mall customers segmentation."
      ],
      "metadata": {
        "id": "b8wUIAk5ggvq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id='DBSCAN description'></a>\n",
        "### 4.2.1 Description<a href='#Top' style=\"text-decoration: none;\">^</a><br>  \n",
        "DBSCAN stands for Density-Based Spatial Clustering of Applications with Noise and is one of clustering algorithms implemented in scikit-learn library. It was proposed by Martin Ester, Hans-Peter Kriegel, Jörg Sander and Xiaowei Xu in 1996 in their famous article <a href=\"https://www.aaai.org/Papers/KDD/1996/KDD96-037.pdf?source=post_page---------------------------\">“A Density-Based Algorithm for Discovering Clusters in Large Spatial Database with Noise”</a>.  \n",
        "\n",
        "As the name of paper suggests the core idea of DBSCAN is around concept of dense regions. The assumption is that natural clusters are composed of densely located points. This requires definition of “dense region”. To do these two parameters are required for DBSCAN algorithm.  \n",
        "* Eps, ε  - distance\n",
        "* MinPts – Minimum number of points within distance Eps  \n",
        "\n",
        "Optionally the distance metric can be specified by a user, but usually Euclidean distance is implemented (like in scikit learn).  \n",
        "\n",
        "A “dense region” is therefore created by a minimum number of points within distance between all of them, Eps. Points which are within this distance but not close to minimum number of other points are treated as “border points”. Remaining ones are noise or outliers. This is shown in the picture below (for MinPts=3). Red points (D) are in a “dense region” – each one has minimum of 3 neighbours within distance Eps. Green points (B) are border ones – they have a neighbour within distance Eps but less than 3. Blue point (O) is an outlier – no neighbours within distance Eps.\n",
        "\n",
        "![DBSCAN.jpg](attachment:DBSCAN.jpg)\n",
        "\n",
        "Advantages of this approach:\n",
        "* it finds number of clusters itself, based on eps and MinPts parameters\n",
        "* It it able to differentiate elongated clusters or clusters surrounded by other clusters in contrary to e.g. K-Means where clusters are always convex.\n",
        "* It is also able to find points not fitting into any cluster – it detects outliers.  \n",
        "\n",
        "The biggest drawback of DBSCAN:\n",
        "* High computational expense of average O(n log(n)) coming from a need to execute a neighbourhood query for each point.\n",
        "* Poorly identifies clusters with various densities\n",
        "\n",
        "There are various variations and extensions proposed by machine learning researchers to DBSCAN algorithm. For example:\n",
        "* W. Jing Ch. Zhao and Ch. Jing proposed <a href=\"https://www.sciencedirect.com/science/article/pii/S1877050919302273\">“An improvement method of DBSCAN algorithm on cloud computing”.</a> to solve problem of scalability.\n",
        "* H. You, L. Chen, J. Yao and X. Wang proposed <a href=\"https://www.sciencedirect.com/science/article/pii/S0020025516300561\">“A three-way clustering method based on an improved DBSCAN algorithm”</a> to overcome problem of clusters with various densities.\n"
      ],
      "metadata": {
        "id": "v4m43q7-ggvq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id='DBSCAN use case'></a>\n",
        "### 4.2.2 Use case - customers segmentation<a href='#Top' style=\"text-decoration: none;\">^</a><br>  \n",
        "\n",
        "The first step - importing DBSCAN from sklearn."
      ],
      "metadata": {
        "id": "ZCSbKJWZggvq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import DBSCAN"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-24T15:06:18.044378Z",
          "iopub.execute_input": "2022-05-24T15:06:18.04503Z",
          "iopub.status.idle": "2022-05-24T15:06:18.049721Z",
          "shell.execute_reply.started": "2022-05-24T15:06:18.044967Z",
          "shell.execute_reply": "2022-05-24T15:06:18.048719Z"
        },
        "trusted": true,
        "id": "9EAiHmF8ggvq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In DBSCAN there are two major hyperparameters:\n",
        "* `eps`\n",
        "* `min_samples`\n",
        "\n",
        "It is difficult arbitrarily to say what values will work the best. Therefore, I will first create a matrix of investigated combinations."
      ],
      "metadata": {
        "id": "OaQORS4Tggvr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import product\n",
        "\n",
        "eps_values = np.arange(8,12.75,0.25) # eps values to be investigated\n",
        "min_samples = np.arange(3,10) # min_samples values to be investigated\n",
        "\n",
        "DBSCAN_params = list(product(eps_values, min_samples))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-24T15:06:18.051663Z",
          "iopub.execute_input": "2022-05-24T15:06:18.052371Z",
          "iopub.status.idle": "2022-05-24T15:06:18.064939Z",
          "shell.execute_reply.started": "2022-05-24T15:06:18.052282Z",
          "shell.execute_reply": "2022-05-24T15:06:18.063935Z"
        },
        "trusted": true,
        "id": "Ggbv2fR9ggvr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Because DBSCAN creates clusters itself based on those two parameters let's check the number of generated clusters."
      ],
      "metadata": {
        "id": "46VzdtM2ggvr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "no_of_clusters = []\n",
        "sil_score = []\n",
        "\n",
        "for p in DBSCAN_params:\n",
        "    DBS_clustering = DBSCAN(eps=p[0], min_samples=p[1]).fit(X_numerics)\n",
        "    no_of_clusters.append(len(np.unique(DBS_clustering.labels_)))\n",
        "    sil_score.append(silhouette_score(X_numerics, DBS_clustering.labels_))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-24T15:14:03.658723Z",
          "iopub.execute_input": "2022-05-24T15:14:03.659127Z",
          "iopub.status.idle": "2022-05-24T15:14:05.137201Z",
          "shell.execute_reply.started": "2022-05-24T15:14:03.659063Z",
          "shell.execute_reply": "2022-05-24T15:14:05.135989Z"
        },
        "trusted": true,
        "id": "KkDF_1bmggvr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A heatplot below shows how many clusters were generated by the DBSCAN algorithm for the respective parameters combinations."
      ],
      "metadata": {
        "id": "1XlsT2nkggvr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tmp = pd.DataFrame.from_records(DBSCAN_params, columns =['Eps', 'Min_samples'])\n",
        "tmp['No_of_clusters'] = no_of_clusters\n",
        "\n",
        "pivot_1 = pd.pivot_table(tmp, values='No_of_clusters', index='Min_samples', columns='Eps')\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12,6))\n",
        "sns.heatmap(pivot_1, annot=True,annot_kws={\"size\": 16}, cmap=\"YlGnBu\", ax=ax)\n",
        "ax.set_title('Number of clusters')\n",
        "plt.show()"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2022-05-24T15:14:05.13993Z",
          "iopub.execute_input": "2022-05-24T15:14:05.140637Z",
          "iopub.status.idle": "2022-05-24T15:14:06.210984Z",
          "shell.execute_reply.started": "2022-05-24T15:14:05.140564Z",
          "shell.execute_reply": "2022-05-24T15:14:06.209703Z"
        },
        "trusted": true,
        "id": "KFBMHEOpggvs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The heatplot above shows, the number of clusters vary from 17 to 4. However, most of the combinations gives 4-7 clusters.\n",
        "To decide which combination to choose I will use a metric - a silhuette score and I will plot it as a heatmap again."
      ],
      "metadata": {
        "id": "mkTHUCZrggvs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tmp = pd.DataFrame.from_records(DBSCAN_params, columns =['Eps', 'Min_samples'])\n",
        "tmp['Sil_score'] = sil_score\n",
        "\n",
        "pivot_1 = pd.pivot_table(tmp, values='Sil_score', index='Min_samples', columns='Eps')\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(18,6))\n",
        "sns.heatmap(pivot_1, annot=True, annot_kws={\"size\": 10}, cmap=\"YlGnBu\", ax=ax)\n",
        "plt.show()"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2022-05-24T15:14:06.213488Z",
          "iopub.execute_input": "2022-05-24T15:14:06.214167Z",
          "iopub.status.idle": "2022-05-24T15:14:07.588442Z",
          "shell.execute_reply.started": "2022-05-24T15:14:06.214089Z",
          "shell.execute_reply": "2022-05-24T15:14:07.587018Z"
        },
        "trusted": true,
        "id": "kdDqE0e4ggvs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Global maximum is 0.26 for `eps`=12.5 and `min_samples`=4."
      ],
      "metadata": {
        "id": "67FgTGCwggvs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DBS_clustering = DBSCAN(eps=12.5, min_samples=4).fit(X_numerics)\n",
        "\n",
        "DBSCAN_clustered = X_numerics.copy()\n",
        "DBSCAN_clustered.loc[:,'Cluster'] = DBS_clustering.labels_ # append labels to points"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2022-05-24T15:14:09.051373Z",
          "iopub.execute_input": "2022-05-24T15:14:09.052016Z",
          "iopub.status.idle": "2022-05-24T15:14:09.063014Z",
          "shell.execute_reply.started": "2022-05-24T15:14:09.051963Z",
          "shell.execute_reply": "2022-05-24T15:14:09.062294Z"
        },
        "trusted": true,
        "id": "RRdCEIkTggvs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking sizes of clusters."
      ],
      "metadata": {
        "id": "JvpJcM0Kggvt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DBSCAN_clust_sizes = DBSCAN_clustered.groupby('Cluster').size().to_frame()\n",
        "DBSCAN_clust_sizes.columns = [\"DBSCAN_size\"]\n",
        "DBSCAN_clust_sizes"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2022-05-24T15:14:09.341382Z",
          "iopub.execute_input": "2022-05-24T15:14:09.341991Z",
          "iopub.status.idle": "2022-05-24T15:14:09.355194Z",
          "shell.execute_reply.started": "2022-05-24T15:14:09.341937Z",
          "shell.execute_reply": "2022-05-24T15:14:09.353861Z"
        },
        "trusted": true,
        "id": "2xy49uasggvt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DBSCAN created 5 clusters plus outliers cluster (-1). Sizes of clusters 0-4 vary significantly - some have only 4 or 8 observations. There are 18 outliers."
      ],
      "metadata": {
        "id": "y1DOnDFQggvt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "outliers = DBSCAN_clustered[DBSCAN_clustered['Cluster']==-1]\n",
        "\n",
        "fig2, (axes) = plt.subplots(1,2,figsize=(12,5))\n",
        "\n",
        "\n",
        "sns.scatterplot('Annual Income (k$)', 'Spending Score (1-100)',\n",
        "                data=DBSCAN_clustered[DBSCAN_clustered['Cluster']!=-1],\n",
        "                hue='Cluster', ax=axes[0], palette='Set1', legend='full', s=45)\n",
        "\n",
        "sns.scatterplot('Age', 'Spending Score (1-100)',\n",
        "                data=DBSCAN_clustered[DBSCAN_clustered['Cluster']!=-1],\n",
        "                hue='Cluster', palette='Set1', ax=axes[1], legend='full', s=45)\n",
        "\n",
        "axes[0].scatter(outliers['Annual Income (k$)'], outliers['Spending Score (1-100)'], s=5, label='outliers', c=\"k\")\n",
        "axes[1].scatter(outliers['Age'], outliers['Spending Score (1-100)'], s=5, label='outliers', c=\"k\")\n",
        "axes[0].legend()\n",
        "axes[1].legend()\n",
        "\n",
        "plt.setp(axes[0].get_legend().get_texts(), fontsize='10')\n",
        "plt.setp(axes[1].get_legend().get_texts(), fontsize='10')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2022-05-24T15:14:09.623298Z",
          "iopub.execute_input": "2022-05-24T15:14:09.62397Z",
          "iopub.status.idle": "2022-05-24T15:14:10.567071Z",
          "shell.execute_reply.started": "2022-05-24T15:14:09.623906Z",
          "shell.execute_reply": "2022-05-24T15:14:10.566113Z"
        },
        "trusted": true,
        "id": "Ff_Y3jc1ggvt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The graph above shows that there are some outliers - these points do not meet distance and minimum samples requirements to be recognised as a cluster."
      ],
      "metadata": {
        "id": "JRP_fAc8ggvt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id='AF'></a>\n",
        "### 4.3 Affinity Propagation<a href='#Top' style=\"text-decoration: none;\">^</a><br>  \n",
        "\n",
        "This chapter describes how Affinity Propagation works and shows its implementation to the mall customers segmentation."
      ],
      "metadata": {
        "id": "tp5qWE6_ggvt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<a id='AF description'></a>\n",
        "### 4.3.1 Description<a href='#Top' style=\"text-decoration: none;\">^</a><br>  \n",
        "Affinity Propagation is a clustering algorithm proposed for the first time by Brendan Frey and Delbert Dueck in 2007 (<a href=\"https://science.sciencemag.org/content/315/5814/972\">\"Clustering by Passing Messages Between Data Points\"</a>). It is built around the concept of sending messages between a pair of points until it converges. These messages are a way of measuring how similar these two points are to each other and can they be exemplars of each other. The algorithm finds an optimum number of clusters itself. This also implies very high time complexity cost of the order O(n²T) where n is the number of samples and T is the number of iterations until convergence. However, a big advantage of AP is the lack of sensitivity to the initialisation criteria. A very good explanation how this algorithm works is in <a href=\"https://towardsdatascience.com/unsupervised-machine-learning-affinity-propagation-algorithm-explained-d1fef85f22c8\">this article</a> on TowardDataScience.com.  \n",
        "    \n",
        "The user is required to specify two parameters:  \n",
        "* Preference which is a negative number and controls how many exemplars are used\n",
        "* Damping factor which prevents numerical oscillations when updating messages\n",
        "\n",
        "Like with any other algorithms there are ongoing efforts to improve it, e.g.:  \n",
        "* P.Ling and his team proposed and <a href=\"https://www.sciencedirect.com/science/article/pii/S0167865516303403#bib0001\">“Adjustable Preference Affinity Propagation (APAP)”</a> algorithm which can produce better clustering results due to improvement to the element preference calculations\n",
        "* H. Wenlong and his team proposed <a href=\"https://www.sciencedirect.com/science/article/pii/S0020025516300561\">“Transfer affinity propagation-based clustering”</a> which out-performs current algorithm in a case of a very small dataset."
      ],
      "metadata": {
        "id": "tuZ6Vmy_ggvu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id='AF use case'></a>\n",
        "### 4.3.2 Use case - customers segmentation<a href='#Top' style=\"text-decoration: none;\">^</a><br>"
      ],
      "metadata": {
        "id": "YBRt_J6Zggvu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import AffinityPropagation"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-24T15:14:12.101056Z",
          "iopub.execute_input": "2022-05-24T15:14:12.101712Z",
          "iopub.status.idle": "2022-05-24T15:14:12.107045Z",
          "shell.execute_reply.started": "2022-05-24T15:14:12.101641Z",
          "shell.execute_reply": "2022-05-24T15:14:12.105874Z"
        },
        "trusted": true,
        "id": "dttKDP7Hggvu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "no_of_clusters = []\n",
        "preferences = range(-20000,-5000,100) # arbitraty chosen range\n",
        "af_sil_score = [] # silouette scores\n",
        "\n",
        "for p in preferences:\n",
        "    AF = AffinityPropagation(preference=p, max_iter=200).fit(X_numerics)\n",
        "    no_of_clusters.append((len(np.unique(AF.labels_))))\n",
        "    af_sil_score.append(silhouette_score(X_numerics, AF.labels_))\n",
        "\n",
        "af_results = pd.DataFrame([preferences, no_of_clusters, af_sil_score], index=['preference','clusters', 'sil_score']).T\n",
        "af_results.sort_values(by='sil_score', ascending=False).head() # display only 5 best scores"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-24T15:14:12.28262Z",
          "iopub.execute_input": "2022-05-24T15:14:12.283128Z",
          "iopub.status.idle": "2022-05-24T15:14:20.693221Z",
          "shell.execute_reply.started": "2022-05-24T15:14:12.283079Z",
          "shell.execute_reply": "2022-05-24T15:14:20.692274Z"
        },
        "trusted": true,
        "id": "_f54dwctggvu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(12,5))\n",
        "ax = sns.lineplot(preferences, af_sil_score, marker='o', ax=ax)\n",
        "ax.set_title(\"Silhouette score method\")\n",
        "ax.set_xlabel(\"number of clusters\")\n",
        "ax.set_ylabel(\"Silhouette score\")\n",
        "ax.axvline(-11800, ls=\"--\", c=\"red\")\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2022-05-24T15:14:20.695722Z",
          "iopub.execute_input": "2022-05-24T15:14:20.696075Z",
          "iopub.status.idle": "2022-05-24T15:14:20.960247Z",
          "shell.execute_reply.started": "2022-05-24T15:14:20.69602Z",
          "shell.execute_reply": "2022-05-24T15:14:20.959251Z"
        },
        "trusted": true,
        "id": "KjwWpL0Yggvu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AF = AffinityPropagation(preference=-11800).fit(X_numerics)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-24T15:14:20.964006Z",
          "iopub.execute_input": "2022-05-24T15:14:20.964317Z",
          "iopub.status.idle": "2022-05-24T15:14:21.007044Z",
          "shell.execute_reply.started": "2022-05-24T15:14:20.964259Z",
          "shell.execute_reply": "2022-05-24T15:14:21.006118Z"
        },
        "trusted": true,
        "id": "_SWV8OXoggvv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AF_clustered = X_numerics.copy()\n",
        "AF_clustered.loc[:,'Cluster'] = AF.labels_ # append labels to points"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-24T15:14:21.010616Z",
          "iopub.execute_input": "2022-05-24T15:14:21.011234Z",
          "iopub.status.idle": "2022-05-24T15:14:21.019256Z",
          "shell.execute_reply.started": "2022-05-24T15:14:21.011144Z",
          "shell.execute_reply": "2022-05-24T15:14:21.01844Z"
        },
        "trusted": true,
        "id": "7VD2MsS4ggvv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AF_clust_sizes = AF_clustered.groupby('Cluster').size().to_frame()\n",
        "AF_clust_sizes.columns = [\"AF_size\"]\n",
        "AF_clust_sizes"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-24T15:14:21.022357Z",
          "iopub.execute_input": "2022-05-24T15:14:21.023157Z",
          "iopub.status.idle": "2022-05-24T15:14:21.040136Z",
          "shell.execute_reply.started": "2022-05-24T15:14:21.023086Z",
          "shell.execute_reply": "2022-05-24T15:14:21.038657Z"
        },
        "trusted": true,
        "id": "H4vYSBsQggvv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig3, (ax_af) = plt.subplots(1,2,figsize=(12,5))\n",
        "\n",
        "\n",
        "scat_1 = sns.scatterplot('Annual Income (k$)', 'Spending Score (1-100)', data=AF_clustered,\n",
        "                hue='Cluster', ax=ax_af[0], palette='Set1', legend='full')\n",
        "\n",
        "sns.scatterplot('Age', 'Spending Score (1-100)', data=AF_clustered,\n",
        "                hue='Cluster', palette='Set1', ax=ax_af[1], legend='full')\n",
        "\n",
        "plt.setp(ax_af[0].get_legend().get_texts(), fontsize='10')\n",
        "plt.setp(ax_af[1].get_legend().get_texts(), fontsize='10')\n",
        "plt.show()"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2022-05-24T15:14:21.043145Z",
          "iopub.execute_input": "2022-05-24T15:14:21.044427Z",
          "iopub.status.idle": "2022-05-24T15:14:21.617618Z",
          "shell.execute_reply.started": "2022-05-24T15:14:21.043512Z",
          "shell.execute_reply": "2022-05-24T15:14:21.616807Z"
        },
        "trusted": true,
        "id": "XogB4IUHggvv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clusters generated by the Affinity Propagation algorithm created relatively even-sized clusters similar to ones created by K-Means."
      ],
      "metadata": {
        "id": "0mTs5NDQggvv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id='Comparison and discussion'></a>\n",
        "## 5. Comparison and discussion <a href='#Top' style=\"text-decoration: none;\">^</a><br>\n",
        "\n",
        "In this chapter clusters genereated by 3 investigated algorithms will be compared and discussed."
      ],
      "metadata": {
        "id": "CkBkkXWqggvv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig1.suptitle('K-Means', fontsize=16)\n",
        "fig1"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2022-05-24T15:14:21.619325Z",
          "iopub.execute_input": "2022-05-24T15:14:21.620001Z",
          "iopub.status.idle": "2022-05-24T15:14:22.1231Z",
          "shell.execute_reply.started": "2022-05-24T15:14:21.619942Z",
          "shell.execute_reply": "2022-05-24T15:14:22.122129Z"
        },
        "trusted": true,
        "id": "5LMtCJuhggvv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig11.suptitle('K-Means', fontsize=16)\n",
        "fig11"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-24T15:14:22.124584Z",
          "iopub.execute_input": "2022-05-24T15:14:22.125079Z",
          "iopub.status.idle": "2022-05-24T15:14:22.731568Z",
          "shell.execute_reply.started": "2022-05-24T15:14:22.125022Z",
          "shell.execute_reply": "2022-05-24T15:14:22.730522Z"
        },
        "trusted": true,
        "id": "PVS76Tn7ggvw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig2.suptitle('DBSCAN', fontsize=16)\n",
        "fig2"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2022-05-24T15:14:22.733174Z",
          "iopub.execute_input": "2022-05-24T15:14:22.733489Z",
          "iopub.status.idle": "2022-05-24T15:14:23.362073Z",
          "shell.execute_reply.started": "2022-05-24T15:14:22.733431Z",
          "shell.execute_reply": "2022-05-24T15:14:23.361158Z"
        },
        "trusted": true,
        "id": "Cccf1E45ggvw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig3.suptitle('Affinity Propagation', fontsize=16)\n",
        "fig3"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2022-05-24T15:14:23.364174Z",
          "iopub.execute_input": "2022-05-24T15:14:23.364524Z",
          "iopub.status.idle": "2022-05-24T15:14:24.039819Z",
          "shell.execute_reply.started": "2022-05-24T15:14:23.364464Z",
          "shell.execute_reply": "2022-05-24T15:14:24.038765Z"
        },
        "trusted": true,
        "id": "AVIGsOalggvw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A table below shows sizes of created clusters. Please note that numbering of clusters is different in each method, e.g. cluster no.0 in K-Means is equivalent of cluster no.2 in DBSCAN and no.2 in Affinity Propagation."
      ],
      "metadata": {
        "id": "uaFfDZsfggvw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clusters = pd.concat([KM6_clust_sizes, DBSCAN_clust_sizes, AF_clust_sizes],axis=1, sort=False)\n",
        "clusters"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-24T15:14:24.041452Z",
          "iopub.execute_input": "2022-05-24T15:14:24.041805Z",
          "iopub.status.idle": "2022-05-24T15:14:24.062503Z",
          "shell.execute_reply.started": "2022-05-24T15:14:24.041741Z",
          "shell.execute_reply": "2022-05-24T15:14:24.06142Z"
        },
        "trusted": true,
        "id": "u-0YqXtVggvw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above comparisons, it is clear that DBSCAN failed to generate reasonable clusters. It is most likely because DBCSAN tries to find clusters based on the density of points. If one of our clusters is less dense than others DBSCAN will produce suboptimal results by not recognising the least dense group as a cluster.\n",
        "\n",
        "In turn, K-Means and Affinity Propagation algorithms created reasonable 6 clusters."
      ],
      "metadata": {
        "id": "njDwIRIkggvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id='References'></a>\n",
        "## References <a href='#Top' style=\"text-decoration: none;\">^</a><br>\n",
        "\n",
        "\n",
        "[1] \tH. Yu, L. Chen and X. Wang, \"A three-way clustering method based on an improved DBSCAN algorithm,\" Physica A: Statistical Mechanics and its Applications, vol. 535, 2019.<br>\n",
        "[2] \tW. Jing, C. Zhao and C. Jiang, \"An improvement method of DBSCAN algorithm on cloud computing,\" Procedia Computer Science, vol. 147, pp. 596-604, 2019. <br>\n",
        "[3] \tM. Ester, H.-P. Kriegel, J. Sander and X. Xu, \"A Density-Based Algorithm for Discovering Clusters in Large Spatial Databases with Noise,\" KDD-96 Proceedings, pp. 226-231, 1996. <br>\n",
        "[4] \tD. Arthur and S. Vassilvitskii, \"k-means++: The Advantages of Careful Seeding,\" Proceedings of the eighteenth annual ACM-SIAM symposium on Discrete algorithms, 2007. <br>\n",
        "[5] \tB. Frey and D. Dueck, \"Clustering by Passing Messages Between Data Points,\" Science, vol. 315, no. 5814, pp. 972-976, 2007. <br>\n",
        "[6] \tP. Li, H. Ji, B. Wang, Z. Huang and H. Li, \"Adjustable preference affinity propagation clustering,\" Pattern Recognition Letters, vol. 85, pp. 72-78, 2017. <br>\n",
        "[7] \tH. Wenlong , F.-l. Chung and S. Wang, \"Transfer affinity propagation-based clustering,\" Information Sciences, vol. 348, pp. 337-356, 2016."
      ],
      "metadata": {
        "id": "QPedM10eggvx"
      }
    }
  ]
}