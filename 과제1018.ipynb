{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOvKTr9yE0iQBRm2Hr45qDa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yujini68/ESAA/blob/main/%EA%B3%BC%EC%A0%9C1018.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 09 추천 시스템\n",
        "\n",
        "### 01 추천 시스템의 개요와 배경\n",
        "\n",
        "- 추천 시스템의 개요\n",
        "\n",
        "아마존 등과 같은 전자 상거래 업체부터 유튜브, 애플 뮤직 등 콘텐츠 포털까지 추천 시스템을 통해 사용자의 취향을 이해하고 맞춤 상품과 콘텐츠를 제공해 조금이라도 오래 자기 사이트에 고객을 머무르게 하기위해 전력을 기울이고 있음\n",
        "\n",
        "- 온라인 스토어의 필수 요소, 추천 시스템\n",
        "\n",
        "추천 시스템을 구성하는 데이터 ex.\n",
        "\n",
        "( 사용자가 어떤 상품을 구매했는가?\n",
        "\n",
        "사용자가 어떤 상품을 둘러보거나 장바구니에 넣었는가?\n",
        "\n",
        "사용자가 평가한 영화 평점은? 제품 평가는?\n",
        "\n",
        "사용자가 스스로 작성한 자신의 취향은?\n",
        "\n",
        "사용자가 무엇을 클릭했는가? )\n",
        "\n",
        "- 추천 시스템의 유형\n",
        "\n",
        "1. 콘텐츠 기반 필터링 방식\n",
        "\n",
        "2. 협업 필터링 방식 (최근점 이웃 협업 필터링, 잠재 요인 협업 필터링)\n",
        "\n",
        "### 02 콘텐츠 기반 필터링 추천 시스템\n",
        "\n",
        "사용자가 특정한 아이템을 매우 선호하는 경우, 그 아이템과 비슷한 콘텐 츠를 가진 다른 아이템을 추천하는 방식\n",
        "\n",
        "### 03 최근접 이웃 협업 필터링\n",
        "\n",
        "협업 필터링 : 사용자가 아이템에 매긴 평점 정보나 상품 구매 이력과 같은 사용자 행동 양식(User Behavior)만을 기반으로 추천을 수행하는 방식, 사용자가 평가한 다른 아이템을 기반으로 사용자가 평가하지 않은 아이템의 예측 평가를 도출하는 방\n",
        "\n",
        "목표 : 사용자-아이템 평점 매트릭스와 같은 축적된 사용자 행동 데이터를 기반으로 사용자가 아직 평가하지 않은 아이템을 에측 평가하는 것\n",
        "\n",
        "최근접 이웃 협업 필터링 (메모리 협업 필터링)\n",
        "\n",
        "사용자 기반 최근접 이웃 방식 :  특정 사용자와 유사한 다른 사용자를 Top-N으로 선정해 이 Top-N 사용자가 좋아하는 아이템을 추천하는 방식\n",
        "\n",
        "아이템 기반 최근접 이웃 방식 : 아이템이 가지는 속성과는 상관없이 사용자들이 그 아이템을 좋아하는지/싫어하는지의 평가 척도가 유사한 아이템을 추천하는 기준이 되는 알고리즘\n",
        "\n",
        "### 04 잠재 요인 협업 필터링\n",
        "\n",
        "- 잠재 요인 협업 필터링의 이해\n",
        "\n",
        "잠재 요인 협업 필터링: 사용자-아이템 평점 매트리스 속에 숨어 있는 잠재 요인을 추출해 추천 예측을 할 수 있게 하는 기법, 행렬 데이터만을 이용해 말 그대로 ‘잠재 요인’을 끄집어내는 것을 의미\n",
        "\n",
        "‘잠재 요인’을 기반으로 다차원 희소 행렬인 사용자一아이템 행렬 데이터를 저차원 밀집 행렬의 사용자-잠재 요인 행렬과 아이템-잠재 요인 행렬의 전치 행렬（즉, 잠재 요인-아이템 행렬）로 분해할 수 있으며, 이렇게 분해된 두 행렬의 내적을 통해 새로운 예측 사용자—아이템 평점 행렬 데이터를 만들어서 사용자가 아직 평점을 부여하지 않는 아이템에 대한 예측 평점을 생성하는 것\n",
        "\n",
        "행렬 분해 : 대규모 다차원 행렬을 SVD와 같은 차원 감소 기법으로 분해하는 과정에서 잠재요인을 추출하는 것\n",
        "\n",
        "- 행렬 분해의 이해\n",
        "\n",
        "행렬 분해 : 다차원의 매트릭스를 저차원 매트릭스로 분해하는 기법\n",
        "\n",
        "ex. SVD(Singular Vector Decomposition), NMF(Non—Negative Matrix Factorization)\n",
        "\n",
        "- 확률적 경사 하강법을 이용한 행렬 분해\n",
        "\n",
        "P 와 Q 행렬로 계산된 예측 R 행렬 값이 실제 R 행렬 값과 가장 최소의 오류를 가질 수 있도록 반복적인 비용 함수 최적화를 통해 P와 Q를 유추해내는 것\n",
        "\n",
        "1. P와 Q를 임의의 값을 가진 행렬로 설정\n",
        "\n",
        "2. P와 Q.T 값을 곱해 예측 R 행렬을 계산하고 예측 R 행렬과 실제 R 행렬에 해당하는 오류 값을 계산\n",
        "\n",
        "3. 이 오류 값을 최소화할 수 있도록 P와 Q 행렬을 적절한 값으로 각각 업데이트\n",
        "\n",
        "4. 만족할 만한 오류 값을 가질 때까지 2, 3번 작업을 반복하면서 P와 Q 값을 업데이트해 근사화\n",
        "\n",
        "- SGD를 이용한 행렬 분해 예제\n",
        "\n",
        "분해하려는 원본 행렬 R을 P와 Q로 분해한 뒤에 다시 P와 Q.T의 내적으로 예측 행렬을 만드는 예제\n",
        "\n",
        "원본 행렬 R을 미정인 널 값(np.NaN)을 포함해 생성하고 분해 행렬 P와 Q는 정규 분포를 가진 랜덤 값으로 초기화, 잠재 요인 차원 3\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Ea_rR-VAw72a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "#원본 행렬 R 생성, 분해 행렬 이와 Q 초기화, 잠재 요인 차원 유는 3으로 설정.\n",
        "R = np.array([[4, np.NaN, np.NaN, 2, np.NaN],\n",
        "              [np.NaN, 5, np.NaN, 3, 1 ],\n",
        "              [np.NaN, np.NaN, 3, 4, 4],\n",
        "              [5, 2, 1, 2, np.NaN]])\n",
        "num_users, num_items = R.shape\n",
        "K=3\n",
        "\n",
        "#P와 Q 행렬의 크기를 지정하고 정규 분포를 가진 임의의 값으로 입력합니다.\n",
        "np.random.seed(1)\n",
        "P = np.random.normal(scale=1./K, size=(num_users, K))\n",
        "Q = np.random.normal(scale=1./K, size=(num_items, K))"
      ],
      "metadata": {
        "id": "N9CAIrE100ii"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "실제 R 행렬과 예측 행렬의 오차를 구하는 get_rmse() 함수 만들기"
      ],
      "metadata": {
        "id": "rbA8Vs501cgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "def get_rmse(R, P, Q, non_zeros):\n",
        "    error = 0\n",
        "    #두 개의 분해된 행렬 으와 Q.T의 내적으로 예측 R 행렬 생성\n",
        "    full_pred_matrix = np.dot(P, Q.T)\n",
        "\n",
        "    #실제 R 행렬에서 널이 아닌 값의 위치 인덱스 추출해 실제 R 행렬과 예측 행렬의 RMSE 추출\n",
        "    x_non_zero_ind = [non_zero[0] for non_zero in non_zeros]\n",
        "    y_non_zero_ind = [non_zero[1] for non_zero in non_zeros]\n",
        "    R_non_zeros = R[x_non_zero_ind, y_non_zero_ind]\n",
        "    full_pred_matrix_non_zeros = full_pred_matrix[x_non_zero_ind, y_non_zero_ind]\n",
        "    mse = mean_squared_error(R_non_zeros, full_pred_matrix_non_zeros)\n",
        "    rmse = np.sqrt(mse)\n",
        "\n",
        "    return rmse\n"
      ],
      "metadata": {
        "id": "VU6aLbfp0y6l"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SGD 기반으로 행렬 분해 수행"
      ],
      "metadata": {
        "id": "to9BnuIv1ico"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#R > 0인 행 위치, 열 위치, 값을 non_zeros 리스트에 저장.\n",
        "non_zeros = [(i, j, R[i, j]) for i in range(num_users) for j in range(num_items) if R[i, j]>0]\n",
        "\n",
        "steps=1000\n",
        "learning_rate=0.01\n",
        "r_lambda=0.01\n",
        "\n",
        "#SGD 기법으로 우와 Q 매트릭스를 계속 업데이트.\n",
        "for step in range(steps):\n",
        "  for i, j, r in non_zeros:\n",
        "    #실제 값과 예측 값의 차이인 오류 값 구함\n",
        "    eij = r - np.dot(P[i, :], Q[j, :].T)\n",
        "    #Regularization을 반영한 SGD 업데이트 공식 적용\n",
        "    P[i, :] = P[i, :] + learning_rate*(eij * Q[j, :] - r_lambda*P[i, :])\n",
        "    Q[j, :] = Q[j, :] + learning_rate*(eij * P[i, :] - r_lambda*Q[j, :])\n",
        "\n",
        "    rmse = get_rmse(R, P, Q, non_zeros)\n",
        "    if (step % 50) == 0 :\n",
        "      print(\"### iteration step : \", step, \" rmse : \", rmse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXUh05DH013Q",
        "outputId": "93927dc5-1f20-4b01-f1a5-5bb1cf89e925"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### iteration step :  0  rmse :  3.261355059488935\n",
            "### iteration step :  0  rmse :  3.26040057174686\n",
            "### iteration step :  0  rmse :  3.253984404542389\n",
            "### iteration step :  0  rmse :  3.2521583839863624\n",
            "### iteration step :  0  rmse :  3.252335303789125\n",
            "### iteration step :  0  rmse :  3.251072196430487\n",
            "### iteration step :  0  rmse :  3.2492449982564864\n",
            "### iteration step :  0  rmse :  3.247416477570409\n",
            "### iteration step :  0  rmse :  3.241926055455223\n",
            "### iteration step :  0  rmse :  3.2400454107613084\n",
            "### iteration step :  0  rmse :  3.240166740749792\n",
            "### iteration step :  0  rmse :  3.2388050277987723\n",
            "### iteration step :  50  rmse :  0.5003190892212748\n",
            "### iteration step :  50  rmse :  0.5001616291326989\n",
            "### iteration step :  50  rmse :  0.49899601202578087\n",
            "### iteration step :  50  rmse :  0.4988483450145831\n",
            "### iteration step :  50  rmse :  0.49895189256631756\n",
            "### iteration step :  50  rmse :  0.49833236830090993\n",
            "### iteration step :  50  rmse :  0.4984148489378701\n",
            "### iteration step :  50  rmse :  0.49792599580240876\n",
            "### iteration step :  50  rmse :  0.4900605568692785\n",
            "### iteration step :  50  rmse :  0.4890370238665435\n",
            "### iteration step :  50  rmse :  0.48869176023997846\n",
            "### iteration step :  50  rmse :  0.4876723101369648\n",
            "### iteration step :  100  rmse :  0.15911521988578564\n",
            "### iteration step :  100  rmse :  0.1588091617801093\n",
            "### iteration step :  100  rmse :  0.1587409221708901\n",
            "### iteration step :  100  rmse :  0.1582856952842508\n",
            "### iteration step :  100  rmse :  0.1583080948216876\n",
            "### iteration step :  100  rmse :  0.15828832993767403\n",
            "### iteration step :  100  rmse :  0.15787486893092847\n",
            "### iteration step :  100  rmse :  0.15792073606567072\n",
            "### iteration step :  100  rmse :  0.15725245215457084\n",
            "### iteration step :  100  rmse :  0.15710664164665206\n",
            "### iteration step :  100  rmse :  0.15690252144190003\n",
            "### iteration step :  100  rmse :  0.1564340384819247\n",
            "### iteration step :  150  rmse :  0.07546004875264435\n",
            "### iteration step :  150  rmse :  0.07544589133447106\n",
            "### iteration step :  150  rmse :  0.07543234329653023\n",
            "### iteration step :  150  rmse :  0.07514800672233914\n",
            "### iteration step :  150  rmse :  0.07518867696418177\n",
            "### iteration step :  150  rmse :  0.0752288950993841\n",
            "### iteration step :  150  rmse :  0.07489318864469259\n",
            "### iteration step :  150  rmse :  0.07493400425933257\n",
            "### iteration step :  150  rmse :  0.07462695506527872\n",
            "### iteration step :  150  rmse :  0.07464332131959663\n",
            "### iteration step :  150  rmse :  0.0746444164156341\n",
            "### iteration step :  150  rmse :  0.07455141311978046\n",
            "### iteration step :  200  rmse :  0.04361016579439073\n",
            "### iteration step :  200  rmse :  0.04370913068953006\n",
            "### iteration step :  200  rmse :  0.04369072102767977\n",
            "### iteration step :  200  rmse :  0.043475549832271414\n",
            "### iteration step :  200  rmse :  0.0435313092537358\n",
            "### iteration step :  200  rmse :  0.04359240037575283\n",
            "### iteration step :  200  rmse :  0.04329647906053838\n",
            "### iteration step :  200  rmse :  0.04332057192123618\n",
            "### iteration step :  200  rmse :  0.04310448294502512\n",
            "### iteration step :  200  rmse :  0.04313550286658552\n",
            "### iteration step :  200  rmse :  0.04313786864806258\n",
            "### iteration step :  200  rmse :  0.04325226798579314\n",
            "### iteration step :  250  rmse :  0.029395183185609734\n",
            "### iteration step :  250  rmse :  0.02954402948437167\n",
            "### iteration step :  250  rmse :  0.02950187436758184\n",
            "### iteration step :  250  rmse :  0.029329609713572593\n",
            "### iteration step :  250  rmse :  0.02940211807327667\n",
            "### iteration step :  250  rmse :  0.02946720568417511\n",
            "### iteration step :  250  rmse :  0.029189294191791375\n",
            "### iteration step :  250  rmse :  0.029198757426747605\n",
            "### iteration step :  250  rmse :  0.028995742260002243\n",
            "### iteration step :  250  rmse :  0.02904415445054541\n",
            "### iteration step :  250  rmse :  0.029049587101179365\n",
            "### iteration step :  250  rmse :  0.029248328780878973\n",
            "### iteration step :  300  rmse :  0.022678715233749362\n",
            "### iteration step :  300  rmse :  0.022844873864300484\n",
            "### iteration step :  300  rmse :  0.022773566650325074\n",
            "### iteration step :  300  rmse :  0.02263234507322516\n",
            "### iteration step :  300  rmse :  0.02272006255153119\n",
            "### iteration step :  300  rmse :  0.022778917442558434\n",
            "### iteration step :  300  rmse :  0.022516243062381223\n",
            "### iteration step :  300  rmse :  0.022515508246519694\n",
            "### iteration step :  300  rmse :  0.02229491665298542\n",
            "### iteration step :  300  rmse :  0.022367287171783136\n",
            "### iteration step :  300  rmse :  0.022392303480653113\n",
            "### iteration step :  300  rmse :  0.022621116143829466\n",
            "### iteration step :  350  rmse :  0.019516973680183715\n",
            "### iteration step :  350  rmse :  0.019681605297160464\n",
            "### iteration step :  350  rmse :  0.019585635379668415\n",
            "### iteration step :  350  rmse :  0.01946716545524988\n",
            "### iteration step :  350  rmse :  0.01956568678979253\n",
            "### iteration step :  350  rmse :  0.019614020075870497\n",
            "### iteration step :  350  rmse :  0.019368393329296258\n",
            "### iteration step :  350  rmse :  0.019361014872334943\n",
            "### iteration step :  350  rmse :  0.019116038405167533\n",
            "### iteration step :  350  rmse :  0.01920981547997513\n",
            "### iteration step :  350  rmse :  0.019255623979392192\n",
            "### iteration step :  350  rmse :  0.019493636196525135\n",
            "### iteration step :  400  rmse :  0.01803666559195465\n",
            "### iteration step :  400  rmse :  0.01819133106334419\n",
            "### iteration step :  400  rmse :  0.018078504374883574\n",
            "### iteration step :  400  rmse :  0.01797554592952707\n",
            "### iteration step :  400  rmse :  0.018080509676855847\n",
            "### iteration step :  400  rmse :  0.018118882879536648\n",
            "### iteration step :  400  rmse :  0.017889686482489363\n",
            "### iteration step :  400  rmse :  0.017878066671070433\n",
            "### iteration step :  400  rmse :  0.01761224433968553\n",
            "### iteration step :  400  rmse :  0.01772096734904666\n",
            "### iteration step :  400  rmse :  0.01778179645659777\n",
            "### iteration step :  400  rmse :  0.018022719092132704\n",
            "### iteration step :  450  rmse :  0.017334045429542092\n",
            "### iteration step :  450  rmse :  0.01747683493759156\n",
            "### iteration step :  450  rmse :  0.01735361907510825\n",
            "### iteration step :  450  rmse :  0.017260553985290646\n",
            "### iteration step :  450  rmse :  0.01736909385010645\n",
            "### iteration step :  450  rmse :  0.017399933857257726\n",
            "### iteration step :  450  rmse :  0.01718431757863743\n",
            "### iteration step :  450  rmse :  0.01716990649625117\n",
            "### iteration step :  450  rmse :  0.01688861579579296\n",
            "### iteration step :  450  rmse :  0.017006638154083088\n",
            "### iteration step :  450  rmse :  0.01707679250866153\n",
            "### iteration step :  450  rmse :  0.01731968595344266\n",
            "### iteration step :  500  rmse :  0.016991609248052833\n",
            "### iteration step :  500  rmse :  0.01712340891578616\n",
            "### iteration step :  500  rmse :  0.01699398405641037\n",
            "### iteration step :  500  rmse :  0.01690707049203008\n",
            "### iteration step :  500  rmse :  0.01701760577221745\n",
            "### iteration step :  500  rmse :  0.017043277556700362\n",
            "### iteration step :  500  rmse :  0.01683803145900356\n",
            "### iteration step :  500  rmse :  0.016821674312725313\n",
            "### iteration step :  500  rmse :  0.016529281264429145\n",
            "### iteration step :  500  rmse :  0.0166528887951985\n",
            "### iteration step :  500  rmse :  0.016728541275490984\n",
            "### iteration step :  500  rmse :  0.016973657887570753\n",
            "### iteration step :  550  rmse :  0.016818969716266233\n",
            "### iteration step :  550  rmse :  0.016941445597444732\n",
            "### iteration step :  550  rmse :  0.0168082592988841\n",
            "### iteration step :  550  rmse :  0.016725234339747562\n",
            "### iteration step :  550  rmse :  0.01683693849143515\n",
            "### iteration step :  550  rmse :  0.016859187050621206\n",
            "### iteration step :  550  rmse :  0.016661644526141564\n",
            "### iteration step :  550  rmse :  0.01664385102006508\n",
            "### iteration step :  550  rmse :  0.016343446075494233\n",
            "### iteration step :  550  rmse :  0.01647044082182643\n",
            "### iteration step :  550  rmse :  0.01654932331426952\n",
            "### iteration step :  550  rmse :  0.016796804595895633\n",
            "### iteration step :  600  rmse :  0.016727439717439115\n",
            "### iteration step :  600  rmse :  0.016842259158977232\n",
            "### iteration step :  600  rmse :  0.016706687924467476\n",
            "### iteration step :  600  rmse :  0.016626255644609397\n",
            "### iteration step :  600  rmse :  0.016738696939262717\n",
            "### iteration step :  600  rmse :  0.016758682415985614\n",
            "### iteration step :  600  rmse :  0.0165668572000528\n",
            "### iteration step :  600  rmse :  0.016547954461110684\n",
            "### iteration step :  600  rmse :  0.016241668760761063\n",
            "### iteration step :  600  rmse :  0.016370800056137867\n",
            "### iteration step :  600  rmse :  0.016451627209257007\n",
            "### iteration step :  600  rmse :  0.01670132290188466\n",
            "### iteration step :  650  rmse :  0.016674291334806343\n",
            "### iteration step :  650  rmse :  0.016782895588885082\n",
            "### iteration step :  650  rmse :  0.016645698091647773\n",
            "### iteration step :  650  rmse :  0.01656714079916223\n",
            "### iteration step :  650  rmse :  0.016680091021598568\n",
            "### iteration step :  650  rmse :  0.016698554271430792\n",
            "### iteration step :  650  rmse :  0.016511017732427972\n",
            "### iteration step :  650  rmse :  0.016491228766905293\n",
            "### iteration step :  650  rmse :  0.01618054419796173\n",
            "### iteration step :  650  rmse :  0.01631111150707529\n",
            "### iteration step :  650  rmse :  0.01639316772050061\n",
            "### iteration step :  650  rmse :  0.01664473691247669\n",
            "### iteration step :  700  rmse :  0.0166383624426085\n",
            "### iteration step :  700  rmse :  0.016741936743323586\n",
            "### iteration step :  700  rmse :  0.016603524189001625\n",
            "### iteration step :  700  rmse :  0.016526454393300468\n",
            "### iteration step :  700  rmse :  0.016639792083379498\n",
            "### iteration step :  700  rmse :  0.016657201345297346\n",
            "### iteration step :  700  rmse :  0.016472928381641428\n",
            "### iteration step :  700  rmse :  0.01645241257047358\n",
            "### iteration step :  700  rmse :  0.016138379086448083\n",
            "### iteration step :  700  rmse :  0.016269993747904915\n",
            "### iteration step :  700  rmse :  0.01635288508504558\n",
            "### iteration step :  700  rmse :  0.016605910068210026\n",
            "### iteration step :  750  rmse :  0.01660906046895522\n",
            "### iteration step :  750  rmse :  0.016708562969098305\n",
            "### iteration step :  750  rmse :  0.016569153528341783\n",
            "### iteration step :  750  rmse :  0.016493367054249922\n",
            "### iteration step :  750  rmse :  0.016607027966870924\n",
            "### iteration step :  750  rmse :  0.01662368102752549\n",
            "### iteration step :  750  rmse :  0.016441927271724666\n",
            "### iteration step :  750  rmse :  0.0164208024653437\n",
            "### iteration step :  750  rmse :  0.016104179990850755\n",
            "### iteration step :  750  rmse :  0.016236628551952913\n",
            "### iteration step :  750  rmse :  0.016320141009292095\n",
            "### iteration step :  750  rmse :  0.016574200475705\n",
            "### iteration step :  800  rmse :  0.016581161561119846\n",
            "### iteration step :  800  rmse :  0.016677363428436936\n",
            "### iteration step :  800  rmse :  0.016537069269613652\n",
            "### iteration step :  800  rmse :  0.0164624613777787\n",
            "### iteration step :  800  rmse :  0.016576412350487568\n",
            "### iteration step :  800  rmse :  0.01659250180024954\n",
            "### iteration step :  800  rmse :  0.01641271740942833\n",
            "### iteration step :  800  rmse :  0.016391072859801518\n",
            "### iteration step :  800  rmse :  0.01607242307736876\n",
            "### iteration step :  800  rmse :  0.016205589842521878\n",
            "### iteration step :  800  rmse :  0.016289609430091494\n",
            "### iteration step :  800  rmse :  0.01654431582921597\n",
            "### iteration step :  850  rmse :  0.01655222898431553\n",
            "### iteration step :  850  rmse :  0.01664575121547569\n",
            "### iteration step :  850  rmse :  0.016504627328190514\n",
            "### iteration step :  850  rmse :  0.016431145801748863\n",
            "### iteration step :  850  rmse :  0.016545370571042432\n",
            "### iteration step :  850  rmse :  0.016561024020105147\n",
            "### iteration step :  850  rmse :  0.016382795627019747\n",
            "### iteration step :  850  rmse :  0.016360700076085824\n",
            "### iteration step :  850  rmse :  0.016040446344395578\n",
            "### iteration step :  850  rmse :  0.016174269580681345\n",
            "### iteration step :  850  rmse :  0.016258737354641353\n",
            "### iteration step :  850  rmse :  0.01651375177473524\n",
            "### iteration step :  900  rmse :  0.016521280433777957\n",
            "### iteration step :  900  rmse :  0.016612624200841405\n",
            "### iteration step :  900  rmse :  0.016470695682261876\n",
            "### iteration step :  900  rmse :  0.016398314989165292\n",
            "### iteration step :  900  rmse :  0.016512806333073466\n",
            "### iteration step :  900  rmse :  0.01652811087350182\n",
            "### iteration step :  900  rmse :  0.016351122754892394\n",
            "### iteration step :  900  rmse :  0.016328629783842166\n",
            "### iteration step :  900  rmse :  0.016007096878603234\n",
            "### iteration step :  900  rmse :  0.016141544071514122\n",
            "### iteration step :  900  rmse :  0.016226430843994055\n",
            "### iteration step :  900  rmse :  0.01648146573819501\n",
            "### iteration step :  950  rmse :  0.016488081335748316\n",
            "### iteration step :  950  rmse :  0.016577652134974717\n",
            "### iteration step :  950  rmse :  0.01643492933498176\n",
            "### iteration step :  950  rmse :  0.0163636366204062\n",
            "### iteration step :  950  rmse :  0.01647839195954869\n",
            "### iteration step :  950  rmse :  0.01649340903060659\n",
            "### iteration step :  950  rmse :  0.016317416842511007\n",
            "### iteration step :  950  rmse :  0.016294568571753248\n",
            "### iteration step :  950  rmse :  0.015972009545965248\n",
            "### iteration step :  950  rmse :  0.0161070634587959\n",
            "### iteration step :  950  rmse :  0.016192355609214733\n",
            "### iteration step :  950  rmse :  0.016447171683479155\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "분해된 P와 Q 함수를 P*Q.T로 예측 행렬을 만들어서 출력"
      ],
      "metadata": {
        "id": "yrE1KObX1m6h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred_matrix = np.dot(P, Q.T)\n",
        "print('예측 행렬:\\n', np.round(pred_matrix, 3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-b2_caBt05wP",
        "outputId": "8ec67a04-ef4e-42e9-da10-4f408f898028"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "예측 행렬:\n",
            " [[3.991 0.897 1.306 2.002 1.663]\n",
            " [6.696 4.978 0.979 2.981 1.003]\n",
            " [6.677 0.391 2.987 3.977 3.986]\n",
            " [4.968 2.005 1.006 2.017 1.14 ]]\n"
          ]
        }
      ]
    }
  ]
}